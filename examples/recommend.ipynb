{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3592a605",
   "metadata": {},
   "source": [
    "## âš ï¸ Proper Evaluation with Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2291ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/matchmaker-dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/matchmaker-dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original interaction data...\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "\n",
      "ğŸ”„ Training model on 80% of data...\n",
      "Reading data... \n",
      "ğŸ”„ Training model on 80% of data...\n",
      "Reading data... âœ…\n",
      "Fitting ALS... \n",
      "ğŸš€ Preparing data...\n",
      "âœ…\n",
      "Fitting ALS... \n",
      "ğŸš€ Preparing data...\n",
      "ğŸ¯ Training maleâ†’female ALS...\n",
      "ğŸ¯ Training maleâ†’female ALS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/matchmaker-dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original interaction data...\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "\n",
      "ğŸ”„ Training model on 80% of data...\n",
      "Reading data... \n",
      "ğŸ”„ Training model on 80% of data...\n",
      "Reading data... âœ…\n",
      "Fitting ALS... \n",
      "ğŸš€ Preparing data...\n",
      "âœ…\n",
      "Fitting ALS... \n",
      "ğŸš€ Preparing data...\n",
      "ğŸ¯ Training maleâ†’female ALS...\n",
      "ğŸ¯ Training maleâ†’female ALS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 18.36it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/matchmaker-dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original interaction data...\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "\n",
      "ğŸ”„ Training model on 80% of data...\n",
      "Reading data... \n",
      "ğŸ”„ Training model on 80% of data...\n",
      "Reading data... âœ…\n",
      "Fitting ALS... \n",
      "ğŸš€ Preparing data...\n",
      "âœ…\n",
      "Fitting ALS... \n",
      "ğŸš€ Preparing data...\n",
      "ğŸ¯ Training maleâ†’female ALS...\n",
      "ğŸ¯ Training maleâ†’female ALS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 18.36it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Training femaleâ†’male ALS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 316.74it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/matchmaker-dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original interaction data...\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "\n",
      "ğŸ”„ Training model on 80% of data...\n",
      "Reading data... \n",
      "ğŸ”„ Training model on 80% of data...\n",
      "Reading data... âœ…\n",
      "Fitting ALS... \n",
      "ğŸš€ Preparing data...\n",
      "âœ…\n",
      "Fitting ALS... \n",
      "ğŸš€ Preparing data...\n",
      "ğŸ¯ Training maleâ†’female ALS...\n",
      "ğŸ¯ Training maleâ†’female ALS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 18.36it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Training femaleâ†’male ALS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 316.74it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting factors to CuPy arrays...\n",
      "âœ… Trained M2F ALS with 31134 males Ã— 32994 females\n",
      "âœ… Trained F2M ALS with 9925 females Ã— 38446 males\n",
      "Complete! âœ…\n",
      "User DF updated âœ…\n",
      "User DF updated âœ…\n",
      "User DF updated âœ…\n",
      "Building FAISS recommender (pop)... User DF updated âœ…\n",
      "Building FAISS recommender (pop)... âœ…\n",
      "âœ… Training complete on train set\n",
      "âœ…\n",
      "âœ… Training complete on train set\n"
     ]
    }
   ],
   "source": [
    "# Proper train/test split evaluation\n",
    "from matchmaker import MatchingEngine\n",
    "import cudf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Load original data and split by timestamp\n",
    "print(\"Loading original interaction data...\")\n",
    "raw_data = cudf.read_csv(\"data/swipes_clean.csv\")\n",
    "\n",
    "# Sort by timestamp and split 80/20\n",
    "raw_data = raw_data.sort_values('timestamp')\n",
    "split_idx = int(len(raw_data) * 0.8)\n",
    "\n",
    "train_data = raw_data.iloc[:split_idx]\n",
    "test_data = raw_data.iloc[split_idx:]\n",
    "\n",
    "print(f\"Train set: {len(train_data):,} interactions\")\n",
    "print(f\"Test set:  {len(test_data):,} interactions\")\n",
    "\n",
    "# Save splits temporarily\n",
    "train_data.to_csv(\"/tmp/train_split.csv\", index=False)\n",
    "test_data.to_csv(\"/tmp/test_split.csv\", index=False)\n",
    "\n",
    "# 2. Build a NEW engine on ONLY the training data\n",
    "print(\"\\nğŸ”„ Training model on 80% of data...\")\n",
    "engine_test = MatchingEngine()\n",
    "engine_test.load_interactions(\"/tmp/train_split.csv\",\n",
    "    decider_col='decidermemberid',\n",
    "    other_col='othermemberid', \n",
    "    like_col='like', \n",
    "    timestamp_col='timestamp',\n",
    "    gender_col='decidergender')\n",
    "engine_test.run_engagement()\n",
    "engine_test.run_elo()\n",
    "engine_test.build_recommender()\n",
    "print(\"âœ… Training complete on train set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673e4c54",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2038f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mutual_compatibility(engine_test, test_data, gender='M', k=100):\n",
    "    \"\"\"\n",
    "    Evaluate mutual compatibility on held-out test set.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    engine_test : MatchingEngine\n",
    "        The trained recommendation engine\n",
    "    test_data : cudf.DataFrame\n",
    "        Test set interactions\n",
    "    gender : str\n",
    "        'M' for males viewing females, 'F' for females viewing males\n",
    "    k : int\n",
    "        Number of recommendations to generate per user\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Evaluation results including metrics and recommendations\n",
    "    \"\"\"\n",
    "    from tqdm import tqdm\n",
    "    import cudf\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Evaluating MUTUAL compatibility - {gender} users viewing {'females' if gender=='M' else 'males'}...\\n\")\n",
    "    \n",
    "    # âš¡ KEEP ON GPU: Filter likes on GPU\n",
    "    test_likes = test_data[test_data['like'] == 1][['decidermemberid', 'othermemberid']]\n",
    "    \n",
    "    # âš¡ KEEP ON GPU: Get gender mapping on GPU\n",
    "    user_genders_df = engine_test.user_df[['user_id', 'gender']].rename(columns={'user_id': 'decidermemberid'})\n",
    "    \n",
    "    # âš¡ KEEP ON GPU: Merge to get genders\n",
    "    test_likes_with_gender = test_likes.merge(user_genders_df, on='decidermemberid', how='left')\n",
    "    \n",
    "    # Build gender-specific like dictionaries\n",
    "    if gender == 'M':\n",
    "        # Males viewing females\n",
    "        male_likes = test_likes_with_gender[test_likes_with_gender['gender'] == 'M']\n",
    "        my_likes = male_likes.groupby('decidermemberid')['othermemberid'].agg(list).to_pandas()\n",
    "        my_likes = {k: set(v) for k, v in my_likes.items()}\n",
    "        \n",
    "        # Females who liked males (for mutual check)\n",
    "        female_likes = test_likes_with_gender[test_likes_with_gender['gender'] == 'F']\n",
    "        their_likes = female_likes.groupby('decidermemberid')['othermemberid'].agg(list).to_pandas()\n",
    "        their_likes = {k: set(v) for k, v in their_likes.items()}\n",
    "        \n",
    "        label = \"MALES VIEWING FEMALES\"\n",
    "        opposite_label = \"female\"\n",
    "    else:\n",
    "        # Females viewing males\n",
    "        female_likes = test_likes_with_gender[test_likes_with_gender['gender'] == 'F']\n",
    "        my_likes = female_likes.groupby('decidermemberid')['othermemberid'].agg(list).to_pandas()\n",
    "        my_likes = {k: set(v) for k, v in my_likes.items()}\n",
    "        \n",
    "        # Males who liked females (for mutual check)\n",
    "        male_likes = test_likes_with_gender[test_likes_with_gender['gender'] == 'M']\n",
    "        their_likes = male_likes.groupby('decidermemberid')['othermemberid'].agg(list).to_pandas()\n",
    "        their_likes = {k: set(v) for k, v in their_likes.items()}\n",
    "        \n",
    "        label = \"FEMALES VIEWING MALES\"\n",
    "        opposite_label = \"male\"\n",
    "    \n",
    "    # Calculate total mutual matches in test set\n",
    "    total_mutual_matches_in_test = 0\n",
    "    for user_id in my_likes:\n",
    "        for other_id in my_likes[user_id]:\n",
    "            # Check if mutual\n",
    "            if user_id in their_likes.get(other_id, set()):\n",
    "                total_mutual_matches_in_test += 1\n",
    "    \n",
    "    # âš¡ KEEP ON GPU: Filter valid users on GPU\n",
    "    user_df_test = engine_test.user_df\n",
    "    valid_users_gpu = user_df_test[user_df_test['user_id'].isin(list(my_likes.keys()))]\n",
    "    test_users_valid = valid_users_gpu['user_id'].to_arrow().to_pylist()\n",
    "    \n",
    "    print(f\"Test users ({gender}) with held-out likes: {len(test_users_valid):,}\")\n",
    "    print(f\"Opposite gender users who liked someone: {len(their_likes):,}\")\n",
    "    print(f\"Total mutual matches in test set: {total_mutual_matches_in_test:,}\")\n",
    "    \n",
    "    if len(test_users_valid) == 0:\n",
    "        print(\"âš ï¸ No test users found\")\n",
    "        return None\n",
    "    \n",
    "    # Generate recommendations for ALL users\n",
    "    print(f\"Generating recommendations for all {len(test_users_valid):,} users...\")\n",
    "    recs_batch = engine_test.recommend_batch(test_users_valid, k=k)\n",
    "    \n",
    "    hits = 0\n",
    "    mutual_hits = 0\n",
    "    all_recs = []\n",
    "    mutual_matches = []\n",
    "    \n",
    "    for user_id in tqdm(test_users_valid, desc=f\"Evaluating {gender}\"):\n",
    "        # Extract user IDs from recommendations\n",
    "        recs = [rec[0] for rec in recs_batch[user_id]]\n",
    "        all_recs.extend(recs)\n",
    "        \n",
    "        # Get who this user liked in test set\n",
    "        actual_likes = my_likes.get(user_id, set())\n",
    "        recommended = set(recs)\n",
    "        \n",
    "        # One-sided hit (user liked someone we recommended)\n",
    "        if len(actual_likes & recommended) > 0:\n",
    "            hits += 1\n",
    "            \n",
    "            # Check for MUTUAL compatibility\n",
    "            for other_id in (actual_likes & recommended):\n",
    "                # Did the other person ALSO like this user in the test set?\n",
    "                if user_id in their_likes.get(other_id, set()):\n",
    "                    mutual_hits += 1\n",
    "                    mutual_matches.append((user_id, other_id))\n",
    "                    break  # Count once per user\n",
    "    \n",
    "    # Calculate metrics\n",
    "    hit_rate = hits / len(test_users_valid)\n",
    "    mutual_hit_rate = mutual_hits / len(test_users_valid)\n",
    "    personalization = len(set(all_recs)) / len(all_recs) if len(all_recs) > 0 else 0\n",
    "    recall_of_matches = mutual_hits / total_mutual_matches_in_test if total_mutual_matches_in_test > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸ“Š HELD-OUT TEST SET EVALUATION (k={k}) - {label}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"One-Sided Hit Rate:    {hit_rate:.2%} ({hits:,}/{len(test_users_valid):,} users)\")\n",
    "    print(f\"   â†³ User liked someone we recommended\")\n",
    "    print(f\"\\nMUTUAL Match Rate:     {mutual_hit_rate:.2%} ({mutual_hits:,}/{len(test_users_valid):,} users)\")\n",
    "    print(f\"   â†³ Both users liked each other (TRUE compatibility!)\")\n",
    "    print(f\"\\nMatch Recall:          {recall_of_matches:.2%} ({mutual_hits:,}/{total_mutual_matches_in_test:,} matches)\")\n",
    "    print(f\"   â†³ Proportion of ALL mutual matches we found in top-{k}\")\n",
    "    print(f\"\\nPersonalization:       {personalization:.2%}\")\n",
    "    print(f\"Unique recs:           {len(set(all_recs)):,}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if mutual_hits > 0:\n",
    "        print(f\"\\nâœ… Found {mutual_hits:,} mutual matches out of {total_mutual_matches_in_test:,} total in test set!\")\n",
    "        print(f\"ğŸ’¡ Match recall of {recall_of_matches:.1%} means we found {recall_of_matches:.1%} of all possible matches in top-{k}!\")\n",
    "    \n",
    "    return {\n",
    "        'gender': gender,\n",
    "        'test_users_valid': test_users_valid,\n",
    "        'all_recs': all_recs,\n",
    "        'hits': hits,\n",
    "        'mutual_hits': mutual_hits,\n",
    "        'mutual_matches': mutual_matches,\n",
    "        'hit_rate': hit_rate,\n",
    "        'mutual_hit_rate': mutual_hit_rate,\n",
    "        'personalization': personalization,\n",
    "        'total_mutual_matches_in_test': total_mutual_matches_in_test,\n",
    "        'recall_of_matches': recall_of_matches\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59d39a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_recommendation_coverage(engine, results_dict, opposite_gender='F'):\n",
    "    \"\"\"\n",
    "    Analyse which users are being recommended and correlate with popularity/engagement.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    engine : MatchingEngine\n",
    "        The trained recommendation engine\n",
    "    results_dict : dict\n",
    "        Results from evaluate_mutual_compatibility function\n",
    "    opposite_gender : str\n",
    "        'F' to analyse females being recommended (to males)\n",
    "        'M' to analyse males being recommended (to females)\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from collections import Counter\n",
    "    from scipy.stats import pearsonr, spearmanr\n",
    "    \n",
    "    all_recs = results_dict['all_recs']\n",
    "    test_users_valid = results_dict['test_users_valid']\n",
    "    \n",
    "    # Get all potential candidates of specified gender\n",
    "    user_df_test = engine.user_df\n",
    "    candidates = user_df_test[user_df_test.gender == opposite_gender].copy().to_pandas()\n",
    "    \n",
    "    # Count how many times each candidate was recommended\n",
    "    rec_counts_dict = Counter(all_recs)\n",
    "    candidates['times_recommended'] = candidates['user_id'].map(lambda x: rec_counts_dict.get(x, 0))\n",
    "    \n",
    "    # Get candidates who were NEVER recommended\n",
    "    never_recommended = candidates[candidates['times_recommended'] == 0]\n",
    "    recommended_users = candidates[candidates['times_recommended'] > 0]\n",
    "    \n",
    "    gender_label = \"Female\" if opposite_gender == 'F' else \"Male\"\n",
    "    \n",
    "    print(f\"\\nğŸ“Š RECOMMENDATION COVERAGE ANALYSIS ({gender_label} Users)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total {gender_label.lower()} users available: {len(candidates):,}\")\n",
    "    print(f\"{gender_label}s recommended at least once: {len(recommended_users):,}\")\n",
    "    print(f\"{gender_label}s NEVER recommended: {len(never_recommended):,} ({len(never_recommended)/len(candidates)*100:.1f}%)\")\n",
    "    \n",
    "    # Check if any users were actually recommended\n",
    "    if len(recommended_users) == 0:\n",
    "        print(f\"\\nâš ï¸  WARNING: No {gender_label.lower()}s were recommended in this evaluation!\")\n",
    "        return candidates, recommended_users, never_recommended\n",
    "    \n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Create scatter plots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # 1. Times Recommended vs elo_rating (Popularity)\n",
    "    axes[0].scatter(candidates['elo_rating'], candidates['times_recommended'], \n",
    "                    alpha=0.5, s=20, c=candidates['times_recommended'], cmap='viridis')\n",
    "    axes[0].set_xlabel('elo_rating Score (Popularity)', fontsize=12)\n",
    "    axes[0].set_ylabel('Times Recommended', fontsize=12)\n",
    "    axes[0].set_title(f'{gender_label} Recommendation Frequency vs Popularity Score', fontsize=14)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_xscale('log')\n",
    "    \n",
    "    # Add correlation\n",
    "    valid_mask = ~candidates['elo_rating'].isna() & ~candidates['times_recommended'].isna()\n",
    "    if valid_mask.sum() > 0:\n",
    "        pearson_corr, _ = pearsonr(candidates[valid_mask]['elo_rating'], \n",
    "                                    candidates[valid_mask]['times_recommended'])\n",
    "        spearman_corr, _ = spearmanr(candidates[valid_mask]['elo_rating'], \n",
    "                                      candidates[valid_mask]['times_recommended'])\n",
    "        axes[0].text(0.05, 0.95, f'Pearson: {pearson_corr:.3f}\\nSpearman: {spearman_corr:.3f}', \n",
    "                    transform=axes[0].transAxes, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # 2. Times Recommended vs Engagement Score\n",
    "    axes[1].scatter(candidates['engagement_score'], candidates['times_recommended'], \n",
    "                    alpha=0.5, s=20, c=candidates['times_recommended'], cmap='plasma')\n",
    "    axes[1].set_xlabel('Engagement Score', fontsize=12)\n",
    "    axes[1].set_ylabel('Times Recommended', fontsize=12)\n",
    "    axes[1].set_title(f'{gender_label} Recommendation Frequency vs Engagement Score', fontsize=14)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add correlation\n",
    "    valid_mask = ~candidates['engagement_score'].isna() & ~candidates['times_recommended'].isna()\n",
    "    if valid_mask.sum() > 0:\n",
    "        pearson_corr, _ = pearsonr(candidates[valid_mask]['engagement_score'], \n",
    "                                    candidates[valid_mask]['times_recommended'])\n",
    "        spearman_corr, _ = spearmanr(candidates[valid_mask]['engagement_score'], \n",
    "                                      candidates[valid_mask]['times_recommended'])\n",
    "        axes[1].text(0.05, 0.95, f'Pearson: {pearson_corr:.3f}\\nSpearman: {spearman_corr:.3f}', \n",
    "                    transform=axes[1].transAxes, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'recommendation_coverage_{opposite_gender}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Detailed stats on never-recommended users\n",
    "    if len(never_recommended) > 0:\n",
    "        print(f\"\\nğŸ“‰ NEVER-RECOMMENDED {gender_label.upper()}S ANALYSIS:\")\n",
    "        print(f\"   â€¢ Avg elo_rating: {never_recommended['elo_rating'].mean():.6f} (vs {candidates['elo_rating'].mean():.6f} overall)\")\n",
    "        print(f\"   â€¢ Avg Engagement: {never_recommended['engagement_score'].mean():.2f} (vs {candidates['engagement_score'].mean():.2f} overall)\")\n",
    "        print(f\"   â€¢ League distribution:\")\n",
    "        for league in ['Bronze', 'Silver', 'Gold', 'Platinum', 'Diamond']:\n",
    "            count = len(never_recommended[never_recommended['league'] == league])\n",
    "            pct = count / len(never_recommended) * 100 if len(never_recommended) > 0 else 0\n",
    "            print(f\"      - {league}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Compare recommended vs never-recommended users\n",
    "    print(f\"\\nğŸ“Š COMPARISON: Recommended vs Never-Recommended {gender_label}s\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    print(f\"\\n{'Metric':<25} {'Recommended':<20} {'Never Recommended':<20}\")\n",
    "    print(f\"{'-'*65}\")\n",
    "    print(f\"{'Count':<25} {len(recommended_users):<20} {len(never_recommended):<20}\")\n",
    "    print(f\"{'Avg elo_rating':<25} {recommended_users['elo_rating'].mean():<20.6f} {never_recommended['elo_rating'].mean():<20.6f}\")\n",
    "    print(f\"{'Median elo_rating':<25} {recommended_users['elo_rating'].median():<20.6f} {never_recommended['elo_rating'].median():<20.6f}\")\n",
    "    print(f\"{'Avg Engagement':<25} {recommended_users['engagement_score'].mean():<20.2f} {never_recommended['engagement_score'].mean():<20.2f}\")\n",
    "    print(f\"{'Median Engagement':<25} {recommended_users['engagement_score'].median():<20.2f} {never_recommended['engagement_score'].median():<20.2f}\")\n",
    "    \n",
    "    return candidates, recommended_users, never_recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe92774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Evaluating MUTUAL compatibility - M users viewing females...\n",
      "\n",
      "Test users (M) with held-out likes: 19,123\n",
      "Opposite gender users who liked someone: 4,725\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 19,123 users...\n",
      "Test users (M) with held-out likes: 19,123\n",
      "Opposite gender users who liked someone: 4,725\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 19,123 users...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Evaluating MUTUAL compatibility - M users viewing females...\n",
      "\n",
      "Test users (M) with held-out likes: 19,123\n",
      "Opposite gender users who liked someone: 4,725\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 19,123 users...\n",
      "Test users (M) with held-out likes: 19,123\n",
      "Opposite gender users who liked someone: 4,725\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 19,123 users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating M: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19123/19123 [00:00<00:00, 127257.82it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Evaluating MUTUAL compatibility - M users viewing females...\n",
      "\n",
      "Test users (M) with held-out likes: 19,123\n",
      "Opposite gender users who liked someone: 4,725\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 19,123 users...\n",
      "Test users (M) with held-out likes: 19,123\n",
      "Opposite gender users who liked someone: 4,725\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 19,123 users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating M: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19123/19123 [00:00<00:00, 127257.82it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“Š HELD-OUT TEST SET EVALUATION (k=100) - MALES VIEWING FEMALES\n",
      "======================================================================\n",
      "One-Sided Hit Rate:    42.75% (8,175/19,123 users)\n",
      "   â†³ User liked someone we recommended\n",
      "\n",
      "MUTUAL Match Rate:     1.01% (194/19,123 users)\n",
      "   â†³ Both users liked each other (TRUE compatibility!)\n",
      "\n",
      "Match Recall:          5.22% (194/3,714 matches)\n",
      "   â†³ Proportion of ALL mutual matches we found in top-100\n",
      "\n",
      "Personalization:       1.30%\n",
      "Unique recs:           22,242\n",
      "======================================================================\n",
      "\n",
      "âœ… Found 194 mutual matches out of 3,714 total in test set!\n",
      "ğŸ’¡ Match recall of 5.2% means we found 5.2% of all possible matches in top-100!\n"
     ]
    }
   ],
   "source": [
    "# Evaluate ALL males viewing females (no sampling)\n",
    "results_males = evaluate_mutual_compatibility(engine_test, test_data, gender='M', k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d8085dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Evaluating MUTUAL compatibility - F users viewing males...\n",
      "\n",
      "Test users (F) with held-out likes: 4,725\n",
      "Opposite gender users who liked someone: 19,123\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 4,725 users...\n",
      "Test users (F) with held-out likes: 4,725\n",
      "Opposite gender users who liked someone: 19,123\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 4,725 users...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Evaluating MUTUAL compatibility - F users viewing males...\n",
      "\n",
      "Test users (F) with held-out likes: 4,725\n",
      "Opposite gender users who liked someone: 19,123\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 4,725 users...\n",
      "Test users (F) with held-out likes: 4,725\n",
      "Opposite gender users who liked someone: 19,123\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 4,725 users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating F: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4725/4725 [00:00<00:00, 78964.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Evaluating MUTUAL compatibility - F users viewing males...\n",
      "\n",
      "Test users (F) with held-out likes: 4,725\n",
      "Opposite gender users who liked someone: 19,123\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 4,725 users...\n",
      "Test users (F) with held-out likes: 4,725\n",
      "Opposite gender users who liked someone: 19,123\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 4,725 users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating F: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4725/4725 [00:00<00:00, 78964.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“Š HELD-OUT TEST SET EVALUATION (k=100) - FEMALES VIEWING MALES\n",
      "======================================================================\n",
      "One-Sided Hit Rate:    2.96% (140/4,725 users)\n",
      "   â†³ User liked someone we recommended\n",
      "\n",
      "MUTUAL Match Rate:     0.99% (47/4,725 users)\n",
      "   â†³ Both users liked each other (TRUE compatibility!)\n",
      "\n",
      "Match Recall:          1.27% (47/3,714 matches)\n",
      "   â†³ Proportion of ALL mutual matches we found in top-100\n",
      "\n",
      "Personalization:       3.36%\n",
      "Unique recs:           13,087\n",
      "======================================================================\n",
      "\n",
      "âœ… Found 47 mutual matches out of 3,714 total in test set!\n",
      "ğŸ’¡ Match recall of 1.3% means we found 1.3% of all possible matches in top-100!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate females viewing males\n",
    "results_females = evaluate_mutual_compatibility(engine_test, test_data, gender='F', k=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ee33a9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99df6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_case_statistics(target_id: int,\n",
    "                         interactions: \"cudf.DataFrame\",\n",
    "                         engine,\n",
    "                         rec_k: int = 30) -> None:\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    print(f\"### Test case statistics for user {target_id} ###\\n\")\n",
    "\n",
    "    decider_df = interactions[interactions[\"decidermemberid\"] == target_id]\n",
    "    total_decisions = len(decider_df)\n",
    "    like_rate = float(decider_df[\"like\"].mean()) if total_decisions else 0.0\n",
    "\n",
    "    likes_given = decider_df[decider_df[\"like\"] == 1]\n",
    "    likes_received = interactions[\n",
    "        (interactions[\"othermemberid\"] == target_id) & (interactions[\"like\"] == 1)\n",
    "    ]\n",
    "\n",
    "    matches = likes_given.merge(\n",
    "        likes_received,\n",
    "        left_on=\"othermemberid\",\n",
    "        right_on=\"decidermemberid\",\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    match_rate = len(matches) / total_decisions if total_decisions else 0.0\n",
    "    match_rate_given_likes = len(matches) / len(likes_given) if len(likes_given) else 0.0\n",
    "\n",
    "    print(f\"Like rate: {like_rate:.2%}\")\n",
    "    print(f\"Match rate: {match_rate:.2%}\")\n",
    "    print(f\"Match rate given likes: {match_rate_given_likes:.2%}\\n\")\n",
    "\n",
    "    recs = engine.recommend_batch([target_id], k=rec_k).get(target_id, [])\n",
    "    if not recs:\n",
    "        print(\"No recommendations available.\\n\")\n",
    "        return\n",
    "\n",
    "    rec_df = pd.DataFrame(recs, columns=[\"candidate_id\", \"score\"])\n",
    "    liked_ids = set(likes_given[\"othermemberid\"].to_pandas().tolist())\n",
    "    rec_df[\"label\"] = rec_df[\"candidate_id\"].apply(lambda cid: 1 if cid in liked_ids else 0)\n",
    "    \n",
    "    # ğŸ” DIAGNOSTIC INFO\n",
    "    print(f\"DEBUG INFO:\")\n",
    "    print(f\"  Total people user liked in dataset: {len(liked_ids)}\")\n",
    "    print(f\"  People with label=1 in top-{rec_k}: {rec_df['label'].sum()}\")\n",
    "    print(f\"  Hit rate in top-{rec_k}: {rec_df['label'].sum() / len(liked_ids) * 100:.1f}%\\n\")\n",
    "    \n",
    "    print(rec_df.nlargest(5, \"score\"), end=\"\\n\\n\")\n",
    "\n",
    "    dcg = 0.0\n",
    "    for rank, rel in enumerate(rec_df.nlargest(rec_k, \"score\")[\"label\"], start=1):\n",
    "        dcg += (2 ** rel - 1) / np.log2(rank + 1)\n",
    "\n",
    "    ideal_labels = rec_df.nlargest(rec_k, \"label\")[\"label\"]\n",
    "    idcg = 0.0\n",
    "    for rank, rel in enumerate(ideal_labels, start=1):\n",
    "        idcg += (2 ** rel - 1) / np.log2(rank + 1)\n",
    "\n",
    "    ndcg_30 = dcg / idcg if idcg > 0 else 0.0\n",
    "    print(f\"NDCG@{rec_k} for user {target_id}: {ndcg_30:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b8efc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Test case statistics for user 1142425 ###\n",
      "\n",
      "Like rate: 6.25%\n",
      "Match rate: 4.17%\n",
      "Match rate given likes: 66.67%\n",
      "\n",
      "DEBUG INFO:\n",
      "  Total people user liked in dataset: 6\n",
      "  People with label=1 in top-30: 1\n",
      "  Hit rate in top-30: 16.7%\n",
      "\n",
      "   candidate_id     score  label\n",
      "0       3832057  0.767458      0\n",
      "1       2978402  0.603261      0\n",
      "2        259471  0.595033      0\n",
      "3        855168  0.497982      0\n",
      "4       2356285  0.441220      0\n",
      "\n",
      "NDCG@30 for user 1142425: 0.2080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_case_statistics(1142425, test_data, engine_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdeb1b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Test case statistics for user 336132 ###\n",
      "\n",
      "Like rate: 28.57%\n",
      "Match rate: 2.38%\n",
      "Match rate given likes: 8.33%\n",
      "\n",
      "DEBUG INFO:\n",
      "  Total people user liked in dataset: 12\n",
      "  People with label=1 in top-30: 0\n",
      "  Hit rate in top-30: 0.0%\n",
      "\n",
      "   candidate_id     score  label\n",
      "0       3866079  0.557231      0\n",
      "1        681097  0.476687      0\n",
      "2       3861867  0.451380      0\n",
      "3        497066  0.451015      0\n",
      "4       2848163  0.404130      0\n",
      "\n",
      "NDCG@30 for user 336132: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_case_statistics(336132, test_data, engine_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3637cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1b6ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, log_loss\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def summarize_classification_pairs(pairs_df):\n",
    "    \"\"\"Add calibrated probabilities, print metrics, and return summary stats.\"\"\"\n",
    "    if pairs_df is None or len(pairs_df) == 0:\n",
    "        print(\"âš ï¸ No pairs generated!\")\n",
    "        return None, {}\n",
    "\n",
    "    pairs_df = pairs_df.copy()\n",
    "    scores = pairs_df['score'].values\n",
    "    z = (scores - scores.mean()) / (scores.std() + 1e-12)  # standardize\n",
    "    pairs_df['proba'] = expit(z)  # sigmoid -> (0, 1)\n",
    "\n",
    "    metrics = {\n",
    "        'num_pairs': int(len(pairs_df)),\n",
    "        'positive_pairs': int(pairs_df['label'].sum()),\n",
    "        'negative_pairs': int((1 - pairs_df['label']).sum()),\n",
    "        'positive_rate': float(pairs_df['label'].mean()),\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        metrics['auc_micro'] = float(roc_auc_score(pairs_df['label'], pairs_df['score']))\n",
    "        metrics['ap_micro'] = float(average_precision_score(pairs_df['label'], pairs_df['score']))\n",
    "        metrics['brier'] = float(brier_score_loss(pairs_df['label'], pairs_df['proba']))\n",
    "        metrics['logloss'] = float(log_loss(pairs_df['label'], pairs_df['proba']))\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error computing metrics: {e}\")\n",
    "        print(f\"Label distribution: {pairs_df['label'].value_counts()}\")\n",
    "        return pairs_df, metrics\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"### ML (ALS RECOMMENDER) PERFORMANCE ON TEST SET ###\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total pairs evaluated:             {metrics['num_pairs']:,}\")\n",
    "    print(f\"Positive pairs (likes):            {metrics['positive_pairs']:,} ({metrics['positive_rate']:.2%})\")\n",
    "    print(f\"Negative pairs (no like):          {metrics['negative_pairs']:,}\")\n",
    "    print(f\"\\nMicro ROC AUC:                     {metrics['auc_micro']:.4f}\")\n",
    "    print(f\"Micro Average Precision (PR-AUC):  {metrics['ap_micro']:.4f}\")\n",
    "    print(f\"Brier score:                       {metrics['brier']:.4f}\")\n",
    "    print(f\"Log loss:                          {metrics['logloss']:.4f}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    return pairs_df, metrics\n",
    "\n",
    "def evaluate_classification_metrics(engine, test_data, sample_size=None, k=100):\n",
    "    \"\"\"\n",
    "    Evaluate classification metrics (AUC, AP, Brier, Log Loss) on test set.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    engine : MatchingEngine\n",
    "        The trained recommendation engine\n",
    "    test_data : cudf.DataFrame\n",
    "        Test set interactions\n",
    "    sample_size : int, optional\n",
    "        Number of users to sample for evaluation (None = all users)\n",
    "    k : int, optional\n",
    "        Number of recommendations generated per user\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple[pd.DataFrame | None, dict]: pairs with labels/scores and summary metrics\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ“Š CLASSIFICATION METRICS EVALUATION ON TEST SET\\n\")\n",
    "\n",
    "    test_users = test_data['decidermemberid'].unique().to_pandas().tolist()\n",
    "\n",
    "    if sample_size and sample_size < len(test_users):\n",
    "        test_users = np.random.choice(test_users, size=sample_size, replace=False).tolist()\n",
    "        print(f\"Sampled {sample_size:,} users from test set\")\n",
    "    else:\n",
    "        print(f\"Evaluating all {len(test_users):,} users in test set\")\n",
    "\n",
    "    test_likes = test_data[test_data['like'] == 1][['decidermemberid', 'othermemberid']]\n",
    "    ground_truth = test_likes.groupby('decidermemberid')['othermemberid'].agg(list).to_pandas()\n",
    "    ground_truth = {k: set(v) for k, v in ground_truth.items()}\n",
    "\n",
    "    print(f\"Generating recommendations for {len(test_users):,} users...\")\n",
    "    recs_batch = engine.recommend_batch(test_users, k=k)\n",
    "\n",
    "    pairs_list = []\n",
    "    for user_id in tqdm(test_users, desc=\"Building pairs\"):\n",
    "        recs = recs_batch.get(user_id, [])\n",
    "        for candidate_id, score in recs:\n",
    "            label = 1 if candidate_id in ground_truth.get(user_id, set()) else 0\n",
    "            pairs_list.append({\n",
    "                'user': user_id,\n",
    "                'item': candidate_id,\n",
    "                'score': score,\n",
    "                'label': label\n",
    "            })\n",
    "\n",
    "    if not pairs_list:\n",
    "        print(\"âš ï¸ No pairs generated!\")\n",
    "        return None, {}\n",
    "\n",
    "    pairs_df = pd.DataFrame(pairs_list)\n",
    "    return summarize_classification_pairs(pairs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd39f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "impressions_df = (\n",
    "    test_data[['decidermemberid', 'othermemberid']]\n",
    "    .rename(columns={'decidermemberid': 'user', 'othermemberid': 'item'})\n",
    "    .drop_duplicates()\n",
    "    .to_pandas()\n",
    " )\n",
    "\n",
    "likes_by_user = (\n",
    "    test_data[test_data['like'] == 1][['decidermemberid', 'othermemberid']]\n",
    "    .rename(columns={'decidermemberid': 'user', 'othermemberid': 'item'})\n",
    "    .groupby('user')['item']\n",
    "    .agg(list)\n",
    "    .to_pandas()\n",
    "    .apply(set)\n",
    "    .to_dict()\n",
    " )\n",
    "\n",
    "def evaluate_classification_metrics_seen_only(pairs_df):\n",
    "    \"\"\"Restrict evaluation to impressions the user actually saw under the logged policy.\"\"\"\n",
    "    if pairs_df is None or len(pairs_df) == 0:\n",
    "        print('âš ï¸ No recommendation pairs supplied.')\n",
    "        return None, {}\n",
    "\n",
    "    filtered_pairs = pairs_df.merge(impressions_df, on=['user', 'item'], how='inner')\n",
    "\n",
    "    if filtered_pairs.empty:\n",
    "        print('âš ï¸ No recommendations overlapped with held-out impressions.')\n",
    "        return None, {}\n",
    "\n",
    "    return summarize_classification_pairs(filtered_pairs)\n",
    "\n",
    "def matched_hits_at_k(pairs_df, k=100):\n",
    "    \"\"\"Compute off-policy Matched Hits@K (precision-style metric) using only seen impressions.\"\"\"\n",
    "    if pairs_df is None or len(pairs_df) == 0:\n",
    "        print('âš ï¸ No recommendation pairs supplied.')\n",
    "        return 0.0, pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    ranked = pairs_df.sort_values(['user', 'score'], ascending=[True, False])\n",
    "    topk = ranked.groupby('user', as_index=False).head(k)\n",
    "\n",
    "    if topk.empty:\n",
    "        print('âš ï¸ No recommendations available for matched hits calculation.')\n",
    "        return 0.0, topk, pd.DataFrame()\n",
    "\n",
    "    seen_topk = topk.merge(impressions_df, on=['user', 'item'], how='inner')\n",
    "\n",
    "    if seen_topk.empty:\n",
    "        print('âš ï¸ None of the recommended pairs were observed under the logged policy.')\n",
    "        return 0.0, seen_topk, pd.DataFrame()\n",
    "\n",
    "    seen_topk['matched_like'] = seen_topk.apply(\n",
    "        lambda row: 1 if row['item'] in likes_by_user.get(row['user'], set()) else 0, axis=1\n",
    "    )\n",
    "\n",
    "    per_user = (\n",
    "        seen_topk.groupby('user')['matched_like']\n",
    "        .agg(['sum', 'count'])\n",
    "        .rename(columns={'sum': 'matched_likes', 'count': 'items_returned'})\n",
    "    )\n",
    "\n",
    "    num_users = len(per_user)\n",
    "    if num_users == 0:\n",
    "        print('âš ï¸ No users with seen recommendations for matched hits calculation.')\n",
    "        return 0.0, seen_topk, per_user\n",
    "\n",
    "    total_items_returned = per_user['items_returned'].sum()\n",
    "    matched_hits = per_user['matched_likes'].sum() / total_items_returned if total_items_returned else 0.0\n",
    "    per_user['matched_hits_at_k'] = per_user['matched_likes'] / per_user['items_returned']\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"### OFF-POLICY MATCHED HITS@K (SEEN IMPRESSIONS) ###\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Users evaluated:                  {num_users:,}\")\n",
    "    print(f\"Total seen recommendations:       {total_items_returned:,}\")\n",
    "    print(f\"Matched Hits@{k} (micro):          {matched_hits:.4f}\")\n",
    "    print(f\"Median per-user matched hits:     {per_user['matched_hits_at_k'].median():.4f}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    return matched_hits, seen_topk, per_user\n",
    "\n",
    "def matched_hits_for_user(engine, user_id, k=100):\n",
    "    \"\"\"Compute Matched Hits@K (micro) for a single user over seen impressions.\"\"\"\n",
    "    recs = engine.recommend_for_user(user_id, k=k) or []\n",
    "    if not recs:\n",
    "        print(f\"âš ï¸ No recommendations available for user {user_id}.\")\n",
    "        return 0.0\n",
    "\n",
    "    rec_df = pd.DataFrame(recs, columns=['item', 'score'])\n",
    "    seen = impressions_df[impressions_df['user'] == user_id]\n",
    "\n",
    "    if seen.empty:\n",
    "        print(f\"âš ï¸ User {user_id} has no logged impressions in the test set.\")\n",
    "        return 0.0\n",
    "\n",
    "    seen_recs = rec_df.merge(seen, on='item', how='inner')\n",
    "\n",
    "    if seen_recs.empty:\n",
    "        print(f\"âš ï¸ None of the top-{k} recommendations for user {user_id} were logged impressions.\")\n",
    "        return 0.0\n",
    "\n",
    "    liked_items = likes_by_user.get(user_id, set())\n",
    "    seen_recs['matched_like'] = seen_recs['item'].isin(liked_items).astype(int)\n",
    "\n",
    "    hits = int(seen_recs['matched_like'].sum())\n",
    "    total = int(len(seen_recs))\n",
    "\n",
    "    rate = hits / total if total else 0.0\n",
    "\n",
    "    print(f\"User {user_id} â€“ Matched Hits@{k} (micro): {rate:.4f} ({hits}/{total} seen recommendations)\")\n",
    "    return rate\n",
    "\n",
    "def logged_hits_for_user(interactions, user_id):\n",
    "    \"\"\"Compute historical hit rate for a user from the logged policy.\"\"\"\n",
    "    user_history = interactions[interactions['decidermemberid'] == user_id][['othermemberid', 'like']]\n",
    "\n",
    "    if len(user_history) == 0:\n",
    "        print(f\"âš ï¸ No logged impressions for user {user_id} in this split.\")\n",
    "        return 0.0\n",
    "\n",
    "    impressions = int(len(user_history))\n",
    "    likes = int(user_history['like'].sum())\n",
    "    rate = likes / impressions if impressions else 0.0\n",
    "\n",
    "    print(f\"User {user_id} â€“ Logged policy hit rate: {rate:.4f} ({likes}/{impressions} impressions)\")\n",
    "    return rate\n",
    "\n",
    "def logged_policy_matched_hits(interactions):\n",
    "    \"\"\"Compute matched hit statistics for the historical logged policy.\"\"\"\n",
    "    df = interactions[['decidermemberid', 'othermemberid', 'like']].to_pandas()\n",
    "\n",
    "    if df.empty:\n",
    "        print('âš ï¸ Interaction data is empty.')\n",
    "        return 0.0, pd.DataFrame()\n",
    "\n",
    "    per_user = (\n",
    "        df.groupby('decidermemberid')\n",
    "        .agg(impressions=('othermemberid', 'count'), matched_likes=('like', 'sum'))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    per_user['matched_hits_rate'] = per_user['matched_likes'] / per_user['impressions']\n",
    "\n",
    "    total_impressions = per_user['impressions'].sum()\n",
    "    total_matched_likes = per_user['matched_likes'].sum()\n",
    "\n",
    "    micro_rate = total_matched_likes / total_impressions if total_impressions else 0.0\n",
    "    median_rate = per_user['matched_hits_rate'].median() if not per_user.empty else 0.0\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"### LOGGED POLICY MATCHED HITS ###\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Users evaluated:                  {len(per_user):,}\")\n",
    "    print(f\"Total logged impressions:         {total_impressions:,}\")\n",
    "    print(f\"Total logged likes (matches):     {int(total_matched_likes):,}\")\n",
    "    print(f\"Matched Hits (micro):             {micro_rate:.4f}\")\n",
    "    print(f\"Median per-user matched hits:     {median_rate:.4f}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    return micro_rate, per_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36463162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring logged impressions...\n",
      "âš ï¸ Assigning fallback score to 140,366 impressions with unsupported gender pairing.\n",
      "âš ï¸ Assigning fallback score to 140,366 impressions with unsupported gender pairing.\n",
      "Evaluating classification metrics on seen impressions...\n",
      "Evaluating classification metrics on seen impressions...\n",
      "\n",
      "======================================================================\n",
      "### ML (ALS RECOMMENDER) PERFORMANCE ON TEST SET ###\n",
      "======================================================================\n",
      "Total pairs evaluated:             1,922,365\n",
      "Positive pairs (likes):            690,014 (35.89%)\n",
      "Negative pairs (no like):          1,232,351\n",
      "\n",
      "Micro ROC AUC:                     0.7089\n",
      "Micro Average Precision (PR-AUC):  0.6058\n",
      "Brier score:                       0.2620\n",
      "Log loss:                          0.7419\n",
      "======================================================================\n",
      "\n",
      "Computing matched hits@100 for recommendations (seen impressions only)...\n",
      "\n",
      "======================================================================\n",
      "### ML (ALS RECOMMENDER) PERFORMANCE ON TEST SET ###\n",
      "======================================================================\n",
      "Total pairs evaluated:             1,922,365\n",
      "Positive pairs (likes):            690,014 (35.89%)\n",
      "Negative pairs (no like):          1,232,351\n",
      "\n",
      "Micro ROC AUC:                     0.7089\n",
      "Micro Average Precision (PR-AUC):  0.6058\n",
      "Brier score:                       0.2620\n",
      "Log loss:                          0.7419\n",
      "======================================================================\n",
      "\n",
      "Computing matched hits@100 for recommendations (seen impressions only)...\n",
      "\n",
      "======================================================================\n",
      "### OFF-POLICY MATCHED HITS@K (SEEN IMPRESSIONS) ###\n",
      "======================================================================\n",
      "Users evaluated:                  30,327\n",
      "Total recommendations scored:      1,127,029\n",
      "Total matched likes (hits):       417,973\n",
      "Matched Hits@100 (micro):         0.3709\n",
      "Median per-user matched hits:     0.2941\n",
      "======================================================================\n",
      "\n",
      "Computing logged policy matched hits for comparison...\n",
      "\n",
      "======================================================================\n",
      "### LOGGED POLICY MATCHED HITS ###\n",
      "======================================================================\n",
      "Users evaluated:                  30,327\n",
      "Total logged impressions:         1,965,578\n",
      "Total logged likes (matches):     699,679\n",
      "Matched Hits (micro):             0.3560\n",
      "Median per-user matched hits:     0.2857\n",
      "======================================================================\n",
      "\n",
      "Computing NDCG@100 from scored impressions...\n",
      "\n",
      "======================================================================\n",
      "### OFF-POLICY MATCHED HITS@K (SEEN IMPRESSIONS) ###\n",
      "======================================================================\n",
      "Users evaluated:                  30,327\n",
      "Total recommendations scored:      1,127,029\n",
      "Total matched likes (hits):       417,973\n",
      "Matched Hits@100 (micro):         0.3709\n",
      "Median per-user matched hits:     0.2941\n",
      "======================================================================\n",
      "\n",
      "Computing logged policy matched hits for comparison...\n",
      "\n",
      "======================================================================\n",
      "### LOGGED POLICY MATCHED HITS ###\n",
      "======================================================================\n",
      "Users evaluated:                  30,327\n",
      "Total logged impressions:         1,965,578\n",
      "Total logged likes (matches):     699,679\n",
      "Matched Hits (micro):             0.3560\n",
      "Median per-user matched hits:     0.2857\n",
      "======================================================================\n",
      "\n",
      "Computing NDCG@100 from scored impressions...\n",
      "\n",
      "======================================================================\n",
      "### OFF-POLICY NDCG@K (LOGGED IMPRESSIONS) ###\n",
      "======================================================================\n",
      "Users evaluated:                  30,327\n",
      "NDCG@100 (micro):                 0.8653\n",
      "Median per-user NDCG:            0.7328\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "### OFF-POLICY NDCG@K (LOGGED IMPRESSIONS) ###\n",
      "======================================================================\n",
      "Users evaluated:                  30,327\n",
      "NDCG@100 (micro):                 0.8653\n",
      "Median per-user NDCG:            0.7328\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compare_old_new_recommendations(user_id, interactions, engine, k=100):\n",
    "    \"\"\"Return recent logged impressions and fresh recommendations for a user.\"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    user_history = (\n",
    "        interactions[interactions['decidermemberid'] == user_id]\n",
    "        .sort_values('timestamp', ascending=False)\n",
    "        [['timestamp', 'othermemberid', 'like']]\n",
    "        .to_pandas()\n",
    "    )\n",
    "\n",
    "    if user_history.empty:\n",
    "        print(f\"âš ï¸ No logged impressions found for user {user_id}.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    user_history = user_history.drop_duplicates(subset='othermemberid', keep='first')\n",
    "    user_history = user_history.rename(columns={'othermemberid': 'candidate_id', 'like': 'liked'})\n",
    "    user_history['liked'] = user_history['liked'].astype(int)\n",
    "\n",
    "    recent_logged = user_history.head(k).copy()\n",
    "\n",
    "    new_recs = engine.recommend_for_user(user_id, k=k) or []\n",
    "    if not new_recs:\n",
    "        print(f\"âš ï¸ Recommender returned no candidates for user {user_id}.\")\n",
    "        return recent_logged, pd.DataFrame()\n",
    "\n",
    "    new_df = pd.DataFrame(new_recs, columns=['candidate_id', 'score'])\n",
    "    new_df['seen_before'] = new_df['candidate_id'].isin(user_history['candidate_id'])\n",
    "    new_df['liked_before'] = new_df['candidate_id'].isin(user_history[user_history['liked'] == 1]['candidate_id'])\n",
    "\n",
    "    return recent_logged, new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6d64c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'User 268553 â€“ recent logged impressions (liked only)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8077960</th>\n",
       "      <td>2021-01-04 23:50:00</td>\n",
       "      <td>1890123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510021</th>\n",
       "      <td>2021-01-04 23:49:56</td>\n",
       "      <td>3204604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9523742</th>\n",
       "      <td>2021-01-04 23:49:53</td>\n",
       "      <td>1643022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732380</th>\n",
       "      <td>2021-01-04 23:49:51</td>\n",
       "      <td>3825592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9589743</th>\n",
       "      <td>2021-01-04 23:49:50</td>\n",
       "      <td>680198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9821300</th>\n",
       "      <td>2021-01-04 23:49:47</td>\n",
       "      <td>1415704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3512927</th>\n",
       "      <td>2021-01-04 23:49:43</td>\n",
       "      <td>107142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8465051</th>\n",
       "      <td>2021-01-04 23:49:17</td>\n",
       "      <td>2793679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113628</th>\n",
       "      <td>2021-01-04 23:49:05</td>\n",
       "      <td>531340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758817</th>\n",
       "      <td>2021-01-04 23:42:18</td>\n",
       "      <td>981466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532510</th>\n",
       "      <td>2021-01-04 23:28:43</td>\n",
       "      <td>683003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626153</th>\n",
       "      <td>2021-01-04 23:28:36</td>\n",
       "      <td>1269010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512977</th>\n",
       "      <td>2021-01-04 23:28:34</td>\n",
       "      <td>1955273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8076881</th>\n",
       "      <td>2021-01-04 23:28:25</td>\n",
       "      <td>247457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557910</th>\n",
       "      <td>2021-01-04 23:28:24</td>\n",
       "      <td>3190271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8085602</th>\n",
       "      <td>2021-01-04 23:28:22</td>\n",
       "      <td>509739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640201</th>\n",
       "      <td>2021-01-04 23:28:20</td>\n",
       "      <td>123632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819908</th>\n",
       "      <td>2021-01-04 23:28:13</td>\n",
       "      <td>2285135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881326</th>\n",
       "      <td>2021-01-04 23:27:38</td>\n",
       "      <td>3268149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477194</th>\n",
       "      <td>2021-01-04 23:27:35</td>\n",
       "      <td>1480722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728033</th>\n",
       "      <td>2021-01-04 23:27:25</td>\n",
       "      <td>266061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779455</th>\n",
       "      <td>2021-01-04 23:27:24</td>\n",
       "      <td>687718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9146270</th>\n",
       "      <td>2021-01-04 23:27:23</td>\n",
       "      <td>965911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8124452</th>\n",
       "      <td>2021-01-04 23:27:18</td>\n",
       "      <td>172965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8463678</th>\n",
       "      <td>2021-01-04 23:20:27</td>\n",
       "      <td>1920148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150459</th>\n",
       "      <td>2021-01-04 23:20:00</td>\n",
       "      <td>376149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  candidate_id  liked\n",
       "8077960  2021-01-04 23:50:00       1890123      1\n",
       "9510021  2021-01-04 23:49:56       3204604      1\n",
       "9523742  2021-01-04 23:49:53       1643022      1\n",
       "5732380  2021-01-04 23:49:51       3825592      1\n",
       "9589743  2021-01-04 23:49:50        680198      1\n",
       "9821300  2021-01-04 23:49:47       1415704      1\n",
       "3512927  2021-01-04 23:49:43        107142      1\n",
       "8465051  2021-01-04 23:49:17       2793679      1\n",
       "8113628  2021-01-04 23:49:05        531340      1\n",
       "3758817  2021-01-04 23:42:18        981466      1\n",
       "5532510  2021-01-04 23:28:43        683003      1\n",
       "3626153  2021-01-04 23:28:36       1269010      1\n",
       "8512977  2021-01-04 23:28:34       1955273      1\n",
       "8076881  2021-01-04 23:28:25        247457      1\n",
       "3557910  2021-01-04 23:28:24       3190271      1\n",
       "8085602  2021-01-04 23:28:22        509739      1\n",
       "5640201  2021-01-04 23:28:20        123632      1\n",
       "9819908  2021-01-04 23:28:13       2285135      1\n",
       "3881326  2021-01-04 23:27:38       3268149      1\n",
       "3477194  2021-01-04 23:27:35       1480722      1\n",
       "7728033  2021-01-04 23:27:25        266061      1\n",
       "3779455  2021-01-04 23:27:24        687718      1\n",
       "9146270  2021-01-04 23:27:23        965911      1\n",
       "8124452  2021-01-04 23:27:18        172965      1\n",
       "8463678  2021-01-04 23:20:27       1920148      1\n",
       "8150459  2021-01-04 23:20:00        376149      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 268553 â€“ Logged policy hit rate: 0.4230 (217/513 impressions)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'User 268553 â€“ new recommendations (seen matches highlighted)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'User 268553 â€“ recent logged impressions (liked only)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8077960</th>\n",
       "      <td>2021-01-04 23:50:00</td>\n",
       "      <td>1890123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510021</th>\n",
       "      <td>2021-01-04 23:49:56</td>\n",
       "      <td>3204604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9523742</th>\n",
       "      <td>2021-01-04 23:49:53</td>\n",
       "      <td>1643022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732380</th>\n",
       "      <td>2021-01-04 23:49:51</td>\n",
       "      <td>3825592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9589743</th>\n",
       "      <td>2021-01-04 23:49:50</td>\n",
       "      <td>680198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9821300</th>\n",
       "      <td>2021-01-04 23:49:47</td>\n",
       "      <td>1415704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3512927</th>\n",
       "      <td>2021-01-04 23:49:43</td>\n",
       "      <td>107142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8465051</th>\n",
       "      <td>2021-01-04 23:49:17</td>\n",
       "      <td>2793679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113628</th>\n",
       "      <td>2021-01-04 23:49:05</td>\n",
       "      <td>531340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758817</th>\n",
       "      <td>2021-01-04 23:42:18</td>\n",
       "      <td>981466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532510</th>\n",
       "      <td>2021-01-04 23:28:43</td>\n",
       "      <td>683003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626153</th>\n",
       "      <td>2021-01-04 23:28:36</td>\n",
       "      <td>1269010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512977</th>\n",
       "      <td>2021-01-04 23:28:34</td>\n",
       "      <td>1955273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8076881</th>\n",
       "      <td>2021-01-04 23:28:25</td>\n",
       "      <td>247457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557910</th>\n",
       "      <td>2021-01-04 23:28:24</td>\n",
       "      <td>3190271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8085602</th>\n",
       "      <td>2021-01-04 23:28:22</td>\n",
       "      <td>509739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640201</th>\n",
       "      <td>2021-01-04 23:28:20</td>\n",
       "      <td>123632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819908</th>\n",
       "      <td>2021-01-04 23:28:13</td>\n",
       "      <td>2285135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881326</th>\n",
       "      <td>2021-01-04 23:27:38</td>\n",
       "      <td>3268149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477194</th>\n",
       "      <td>2021-01-04 23:27:35</td>\n",
       "      <td>1480722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728033</th>\n",
       "      <td>2021-01-04 23:27:25</td>\n",
       "      <td>266061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779455</th>\n",
       "      <td>2021-01-04 23:27:24</td>\n",
       "      <td>687718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9146270</th>\n",
       "      <td>2021-01-04 23:27:23</td>\n",
       "      <td>965911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8124452</th>\n",
       "      <td>2021-01-04 23:27:18</td>\n",
       "      <td>172965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8463678</th>\n",
       "      <td>2021-01-04 23:20:27</td>\n",
       "      <td>1920148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150459</th>\n",
       "      <td>2021-01-04 23:20:00</td>\n",
       "      <td>376149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  candidate_id  liked\n",
       "8077960  2021-01-04 23:50:00       1890123      1\n",
       "9510021  2021-01-04 23:49:56       3204604      1\n",
       "9523742  2021-01-04 23:49:53       1643022      1\n",
       "5732380  2021-01-04 23:49:51       3825592      1\n",
       "9589743  2021-01-04 23:49:50        680198      1\n",
       "9821300  2021-01-04 23:49:47       1415704      1\n",
       "3512927  2021-01-04 23:49:43        107142      1\n",
       "8465051  2021-01-04 23:49:17       2793679      1\n",
       "8113628  2021-01-04 23:49:05        531340      1\n",
       "3758817  2021-01-04 23:42:18        981466      1\n",
       "5532510  2021-01-04 23:28:43        683003      1\n",
       "3626153  2021-01-04 23:28:36       1269010      1\n",
       "8512977  2021-01-04 23:28:34       1955273      1\n",
       "8076881  2021-01-04 23:28:25        247457      1\n",
       "3557910  2021-01-04 23:28:24       3190271      1\n",
       "8085602  2021-01-04 23:28:22        509739      1\n",
       "5640201  2021-01-04 23:28:20        123632      1\n",
       "9819908  2021-01-04 23:28:13       2285135      1\n",
       "3881326  2021-01-04 23:27:38       3268149      1\n",
       "3477194  2021-01-04 23:27:35       1480722      1\n",
       "7728033  2021-01-04 23:27:25        266061      1\n",
       "3779455  2021-01-04 23:27:24        687718      1\n",
       "9146270  2021-01-04 23:27:23        965911      1\n",
       "8124452  2021-01-04 23:27:18        172965      1\n",
       "8463678  2021-01-04 23:20:27       1920148      1\n",
       "8150459  2021-01-04 23:20:00        376149      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 268553 â€“ Logged policy hit rate: 0.4230 (217/513 impressions)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'User 268553 â€“ new recommendations (seen matches highlighted)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>score</th>\n",
       "      <th>seen_before</th>\n",
       "      <th>liked_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3866599</td>\n",
       "      <td>0.910172</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3869985</td>\n",
       "      <td>0.649383</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3853373</td>\n",
       "      <td>0.630649</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1890123</td>\n",
       "      <td>0.591339</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    candidate_id     score  seen_before  liked_before\n",
       "1        3866599  0.910172         True         False\n",
       "15       3869985  0.649383         True          True\n",
       "19       3853373  0.630649         True          True\n",
       "27       1890123  0.591339         True          True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'User 268553 â€“ recent logged impressions (liked only)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8077960</th>\n",
       "      <td>2021-01-04 23:50:00</td>\n",
       "      <td>1890123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510021</th>\n",
       "      <td>2021-01-04 23:49:56</td>\n",
       "      <td>3204604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9523742</th>\n",
       "      <td>2021-01-04 23:49:53</td>\n",
       "      <td>1643022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732380</th>\n",
       "      <td>2021-01-04 23:49:51</td>\n",
       "      <td>3825592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9589743</th>\n",
       "      <td>2021-01-04 23:49:50</td>\n",
       "      <td>680198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9821300</th>\n",
       "      <td>2021-01-04 23:49:47</td>\n",
       "      <td>1415704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3512927</th>\n",
       "      <td>2021-01-04 23:49:43</td>\n",
       "      <td>107142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8465051</th>\n",
       "      <td>2021-01-04 23:49:17</td>\n",
       "      <td>2793679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113628</th>\n",
       "      <td>2021-01-04 23:49:05</td>\n",
       "      <td>531340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758817</th>\n",
       "      <td>2021-01-04 23:42:18</td>\n",
       "      <td>981466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532510</th>\n",
       "      <td>2021-01-04 23:28:43</td>\n",
       "      <td>683003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626153</th>\n",
       "      <td>2021-01-04 23:28:36</td>\n",
       "      <td>1269010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512977</th>\n",
       "      <td>2021-01-04 23:28:34</td>\n",
       "      <td>1955273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8076881</th>\n",
       "      <td>2021-01-04 23:28:25</td>\n",
       "      <td>247457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557910</th>\n",
       "      <td>2021-01-04 23:28:24</td>\n",
       "      <td>3190271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8085602</th>\n",
       "      <td>2021-01-04 23:28:22</td>\n",
       "      <td>509739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640201</th>\n",
       "      <td>2021-01-04 23:28:20</td>\n",
       "      <td>123632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819908</th>\n",
       "      <td>2021-01-04 23:28:13</td>\n",
       "      <td>2285135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881326</th>\n",
       "      <td>2021-01-04 23:27:38</td>\n",
       "      <td>3268149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477194</th>\n",
       "      <td>2021-01-04 23:27:35</td>\n",
       "      <td>1480722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728033</th>\n",
       "      <td>2021-01-04 23:27:25</td>\n",
       "      <td>266061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779455</th>\n",
       "      <td>2021-01-04 23:27:24</td>\n",
       "      <td>687718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9146270</th>\n",
       "      <td>2021-01-04 23:27:23</td>\n",
       "      <td>965911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8124452</th>\n",
       "      <td>2021-01-04 23:27:18</td>\n",
       "      <td>172965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8463678</th>\n",
       "      <td>2021-01-04 23:20:27</td>\n",
       "      <td>1920148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150459</th>\n",
       "      <td>2021-01-04 23:20:00</td>\n",
       "      <td>376149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  candidate_id  liked\n",
       "8077960  2021-01-04 23:50:00       1890123      1\n",
       "9510021  2021-01-04 23:49:56       3204604      1\n",
       "9523742  2021-01-04 23:49:53       1643022      1\n",
       "5732380  2021-01-04 23:49:51       3825592      1\n",
       "9589743  2021-01-04 23:49:50        680198      1\n",
       "9821300  2021-01-04 23:49:47       1415704      1\n",
       "3512927  2021-01-04 23:49:43        107142      1\n",
       "8465051  2021-01-04 23:49:17       2793679      1\n",
       "8113628  2021-01-04 23:49:05        531340      1\n",
       "3758817  2021-01-04 23:42:18        981466      1\n",
       "5532510  2021-01-04 23:28:43        683003      1\n",
       "3626153  2021-01-04 23:28:36       1269010      1\n",
       "8512977  2021-01-04 23:28:34       1955273      1\n",
       "8076881  2021-01-04 23:28:25        247457      1\n",
       "3557910  2021-01-04 23:28:24       3190271      1\n",
       "8085602  2021-01-04 23:28:22        509739      1\n",
       "5640201  2021-01-04 23:28:20        123632      1\n",
       "9819908  2021-01-04 23:28:13       2285135      1\n",
       "3881326  2021-01-04 23:27:38       3268149      1\n",
       "3477194  2021-01-04 23:27:35       1480722      1\n",
       "7728033  2021-01-04 23:27:25        266061      1\n",
       "3779455  2021-01-04 23:27:24        687718      1\n",
       "9146270  2021-01-04 23:27:23        965911      1\n",
       "8124452  2021-01-04 23:27:18        172965      1\n",
       "8463678  2021-01-04 23:20:27       1920148      1\n",
       "8150459  2021-01-04 23:20:00        376149      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 268553 â€“ Logged policy hit rate: 0.4230 (217/513 impressions)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'User 268553 â€“ new recommendations (seen matches highlighted)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>score</th>\n",
       "      <th>seen_before</th>\n",
       "      <th>liked_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3866599</td>\n",
       "      <td>0.910172</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3869985</td>\n",
       "      <td>0.649383</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3853373</td>\n",
       "      <td>0.630649</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1890123</td>\n",
       "      <td>0.591339</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    candidate_id     score  seen_before  liked_before\n",
       "1        3866599  0.910172         True         False\n",
       "15       3869985  0.649383         True          True\n",
       "19       3853373  0.630649         True          True\n",
       "27       1890123  0.591339         True          True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 268553 â€“ Matched Hits@50: 0.7500 (3/4 seen recommendations)\n"
     ]
    }
   ],
   "source": [
    "k = 50\n",
    "example_users = [268553]\n",
    "comparison_results = {}\n",
    "for uid in example_users:\n",
    "    recent_logged, new_recs = compare_old_new_recommendations(uid, test_data, engine_test, k=k)\n",
    "    comparison_results[uid] = {'logged': recent_logged, 'new': new_recs}\n",
    "    display(f\"User {uid} â€“ recent logged impressions (liked only)\")\n",
    "    display(recent_logged[recent_logged['liked'] == 1])\n",
    "    logged_hits_for_user(test_data, uid)\n",
    "    display(f\"User {uid} â€“ new recommendations (seen matches highlighted)\")\n",
    "    if not new_recs.empty:\n",
    "        display(new_recs[new_recs['seen_before'] | new_recs['liked_before']])\n",
    "    print()\n",
    "    matched_hits_for_user(engine_test, uid, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a7bd2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "### OFF-POLICY NDCG@K (LOGGED IMPRESSIONS) ###\n",
      "======================================================================\n",
      "Users evaluated:                  30,327\n",
      "NDCG@100 (micro):                 0.8653\n",
      "Median per-user NDCG:            0.7328\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate the raw recommendation pairs\n",
    "pairs_df, overall_metrics = evaluate_classification_metrics(engine_test, test_data, sample_size=40000, k=100)\n",
    "\n",
    "print()\n",
    "\n",
    "# re-score using only impressions the user actually saw\n",
    "seen_pairs_df, seen_metrics = evaluate_classification_metrics_seen_only(pairs_df)\n",
    "\n",
    "print()\n",
    "\n",
    "# compute matched hits@K (off-policy precision style metric)\n",
    "matched_hits, topk_matched_pairs, per_user_matched = matched_hits_at_k(pairs_df, k=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matchmaker-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
