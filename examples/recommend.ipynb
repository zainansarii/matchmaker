{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3592a605",
   "metadata": {},
   "source": [
    "## âš ï¸ Proper Evaluation with Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2291ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/matchmaker-dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original interaction data...\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n"
     ]
    }
   ],
   "source": [
    "# Proper train/test split evaluation\n",
    "from matchmaker import matchmaker\n",
    "import cudf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Load original data and split by timestamp\n",
    "print(\"Loading original interaction data...\")\n",
    "raw_data = cudf.read_csv(\"data/swipes_clean.csv\")\n",
    "\n",
    "# Sort by timestamp and split 80/20\n",
    "raw_data = raw_data.sort_values('timestamp')\n",
    "split_idx = int(len(raw_data) * 0.8)\n",
    "\n",
    "train_data = raw_data.iloc[:split_idx]\n",
    "test_data = raw_data.iloc[split_idx:]\n",
    "\n",
    "print(f\"Train set: {len(train_data):,} interactions\")\n",
    "print(f\"Test set:  {len(test_data):,} interactions\")\n",
    "\n",
    "# Save splits temporarily\n",
    "train_data.to_csv(\"/tmp/train_split.csv\", index=False)\n",
    "test_data.to_csv(\"/tmp/test_split.csv\", index=False)\n",
    "\n",
    "# 2. Build a NEW engine on ONLY the training data\n",
    "print(\"\\nðŸ”„ Training model on 80% of data...\")\n",
    "engine_test = matchmaker.MatchingEngine()\n",
    "engine_test.load_interactions(\"/tmp/train_split.csv\",\n",
    "    decider_col='decidermemberid',\n",
    "    other_col='othermemberid', \n",
    "    like_col='like', \n",
    "    timestamp_col='timestamp',\n",
    "    gender_col='decidergender')\n",
    "engine_test.run_engagement()\n",
    "engine_test.run_popularity()\n",
    "engine_test.build_recommender()\n",
    "\n",
    "print(\"âœ… Training complete on train set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Evaluate on HELD-OUT test set\n",
    "print(\"\\nðŸ“Š Evaluating on held-out test set (20% of data)...\\n\")\n",
    "\n",
    "# Get test set likes (ground truth)\n",
    "test_likes_df = test_data[test_data['like'] == 1][['decidermemberid', 'othermemberid']].to_pandas()\n",
    "test_likes = test_likes_df.groupby('decidermemberid')['othermemberid'].apply(list).to_dict()\n",
    "\n",
    "# Get users who have likes in BOTH train and test (so we can recommend)\n",
    "user_df_test = engine_test.user_df\n",
    "test_users_sample = user_df_test[user_df_test.gender=='M'].dropna().sample(min(1000, len(user_df_test))).user_id.to_arrow().to_pylist()\n",
    "test_users_valid = [u for u in test_users_sample if u in test_likes]\n",
    "\n",
    "print(f\"Test users with held-out likes: {len(test_users_valid)}\")\n",
    "\n",
    "if len(test_users_valid) == 0:\n",
    "    print(\"âš ï¸ No test users found - need users who appear in both train and test sets\")\n",
    "else:\n",
    "    # Generate recommendations using model trained on train set\n",
    "    recs_batch = engine_test.recommend_batch(test_users_valid, k=100)\n",
    "    \n",
    "    hits = 0\n",
    "    all_recs = []\n",
    "    \n",
    "    for user_id in tqdm(test_users_valid, desc=\"Evaluating\"):\n",
    "        # Extract user IDs from recommendations\n",
    "        recs = [rec[0] for rec in recs_batch[user_id]]\n",
    "        all_recs.extend(recs)\n",
    "        \n",
    "        # Check if any recommended users were actually liked IN THE TEST SET (unseen data)\n",
    "        actual = set(test_likes[user_id])\n",
    "        recommended = set(recs)\n",
    "        \n",
    "        if len(actual & recommended) > 0:\n",
    "            hits += 1\n",
    "    \n",
    "    # Calculate metrics\n",
    "    hit_rate = hits / len(test_users_valid)\n",
    "    personalization = len(set(all_recs)) / len(all_recs) if len(all_recs) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"ðŸ“Š HELD-OUT TEST SET EVALUATION (k=100)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Hit Rate:        {hit_rate:.2%} ({hits}/{len(test_users_valid)} users)\")\n",
    "    print(f\"Personalization: {personalization:.2%}\")\n",
    "    print(f\"Unique recs:     {len(set(all_recs)):,}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(\"\\nâœ… This is the TRUE performance on unseen data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f333a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matchmaker-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
