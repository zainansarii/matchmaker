{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3592a605",
   "metadata": {},
   "source": [
    "## ⚠️ Proper Evaluation with Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2291ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/matchmaker-dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/matchmaker-dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original interaction data...\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "\n",
      "🔄 Training model on 80% of data...\n",
      "Reading data... \n",
      "🔄 Training model on 80% of data...\n",
      "Reading data... ✅\n",
      "Fitting ALS... \n",
      "🚀 Preparing data...\n",
      "✅\n",
      "Fitting ALS... \n",
      "🚀 Preparing data...\n",
      "🎯 Training male→female ALS...\n",
      "🎯 Training male→female ALS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/matchmaker-dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original interaction data...\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "\n",
      "🔄 Training model on 80% of data...\n",
      "Reading data... \n",
      "🔄 Training model on 80% of data...\n",
      "Reading data... ✅\n",
      "Fitting ALS... \n",
      "🚀 Preparing data...\n",
      "✅\n",
      "Fitting ALS... \n",
      "🚀 Preparing data...\n",
      "🎯 Training male→female ALS...\n",
      "🎯 Training male→female ALS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.36it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/matchmaker-dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original interaction data...\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "\n",
      "🔄 Training model on 80% of data...\n",
      "Reading data... \n",
      "🔄 Training model on 80% of data...\n",
      "Reading data... ✅\n",
      "Fitting ALS... \n",
      "🚀 Preparing data...\n",
      "✅\n",
      "Fitting ALS... \n",
      "🚀 Preparing data...\n",
      "🎯 Training male→female ALS...\n",
      "🎯 Training male→female ALS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.36it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Training female→male ALS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 316.74it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/matchmaker-dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original interaction data...\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "Train set: 7,862,310 interactions\n",
      "Test set:  1,965,578 interactions\n",
      "\n",
      "🔄 Training model on 80% of data...\n",
      "Reading data... \n",
      "🔄 Training model on 80% of data...\n",
      "Reading data... ✅\n",
      "Fitting ALS... \n",
      "🚀 Preparing data...\n",
      "✅\n",
      "Fitting ALS... \n",
      "🚀 Preparing data...\n",
      "🎯 Training male→female ALS...\n",
      "🎯 Training male→female ALS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.36it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Training female→male ALS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 316.74it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Converting factors to CuPy arrays...\n",
      "✅ Trained M2F ALS with 31134 males × 32994 females\n",
      "✅ Trained F2M ALS with 9925 females × 38446 males\n",
      "Complete! ✅\n",
      "User DF updated ✅\n",
      "User DF updated ✅\n",
      "User DF updated ✅\n",
      "Building FAISS recommender (pop)... User DF updated ✅\n",
      "Building FAISS recommender (pop)... ✅\n",
      "✅ Training complete on train set\n",
      "✅\n",
      "✅ Training complete on train set\n"
     ]
    }
   ],
   "source": [
    "# Proper train/test split evaluation\n",
    "from matchmaker import MatchingEngine\n",
    "import cudf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Load original data and split by timestamp\n",
    "print(\"Loading original interaction data...\")\n",
    "raw_data = cudf.read_csv(\"data/swipes_clean.csv\")\n",
    "\n",
    "# Sort by timestamp and split 80/20\n",
    "raw_data = raw_data.sort_values('timestamp')\n",
    "split_idx = int(len(raw_data) * 0.8)\n",
    "\n",
    "train_data = raw_data.iloc[:split_idx]\n",
    "test_data = raw_data.iloc[split_idx:]\n",
    "\n",
    "print(f\"Train set: {len(train_data):,} interactions\")\n",
    "print(f\"Test set:  {len(test_data):,} interactions\")\n",
    "\n",
    "# Save splits temporarily\n",
    "train_data.to_csv(\"/tmp/train_split.csv\", index=False)\n",
    "test_data.to_csv(\"/tmp/test_split.csv\", index=False)\n",
    "\n",
    "# 2. Build a NEW engine on ONLY the training data\n",
    "print(\"\\n🔄 Training model on 80% of data...\")\n",
    "engine_test = MatchingEngine()\n",
    "engine_test.load_interactions(\"/tmp/train_split.csv\",\n",
    "    decider_col='decidermemberid',\n",
    "    other_col='othermemberid', \n",
    "    like_col='like', \n",
    "    timestamp_col='timestamp',\n",
    "    gender_col='decidergender')\n",
    "engine_test.run_engagement()\n",
    "engine_test.run_elo()\n",
    "engine_test.build_recommender()\n",
    "print(\"✅ Training complete on train set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673e4c54",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2038f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mutual_compatibility(engine_test, test_data, gender='M', k=100):\n",
    "    \"\"\"\n",
    "    Evaluate mutual compatibility on held-out test set.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    engine_test : MatchingEngine\n",
    "        The trained recommendation engine\n",
    "    test_data : cudf.DataFrame\n",
    "        Test set interactions\n",
    "    gender : str\n",
    "        'M' for males viewing females, 'F' for females viewing males\n",
    "    k : int\n",
    "        Number of recommendations to generate per user\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Evaluation results including metrics and recommendations\n",
    "    \"\"\"\n",
    "    from tqdm import tqdm\n",
    "    import cudf\n",
    "    \n",
    "    print(f\"\\n📊 Evaluating MUTUAL compatibility - {gender} users viewing {'females' if gender=='M' else 'males'}...\\n\")\n",
    "    \n",
    "    # ⚡ KEEP ON GPU: Filter likes on GPU\n",
    "    test_likes = test_data[test_data['like'] == 1][['decidermemberid', 'othermemberid']]\n",
    "    \n",
    "    # ⚡ KEEP ON GPU: Get gender mapping on GPU\n",
    "    user_genders_df = engine_test.user_df[['user_id', 'gender']].rename(columns={'user_id': 'decidermemberid'})\n",
    "    \n",
    "    # ⚡ KEEP ON GPU: Merge to get genders\n",
    "    test_likes_with_gender = test_likes.merge(user_genders_df, on='decidermemberid', how='left')\n",
    "    \n",
    "    # Build gender-specific like dictionaries\n",
    "    if gender == 'M':\n",
    "        # Males viewing females\n",
    "        male_likes = test_likes_with_gender[test_likes_with_gender['gender'] == 'M']\n",
    "        my_likes = male_likes.groupby('decidermemberid')['othermemberid'].agg(list).to_pandas()\n",
    "        my_likes = {k: set(v) for k, v in my_likes.items()}\n",
    "        \n",
    "        # Females who liked males (for mutual check)\n",
    "        female_likes = test_likes_with_gender[test_likes_with_gender['gender'] == 'F']\n",
    "        their_likes = female_likes.groupby('decidermemberid')['othermemberid'].agg(list).to_pandas()\n",
    "        their_likes = {k: set(v) for k, v in their_likes.items()}\n",
    "        \n",
    "        label = \"MALES VIEWING FEMALES\"\n",
    "        opposite_label = \"female\"\n",
    "    else:\n",
    "        # Females viewing males\n",
    "        female_likes = test_likes_with_gender[test_likes_with_gender['gender'] == 'F']\n",
    "        my_likes = female_likes.groupby('decidermemberid')['othermemberid'].agg(list).to_pandas()\n",
    "        my_likes = {k: set(v) for k, v in my_likes.items()}\n",
    "        \n",
    "        # Males who liked females (for mutual check)\n",
    "        male_likes = test_likes_with_gender[test_likes_with_gender['gender'] == 'M']\n",
    "        their_likes = male_likes.groupby('decidermemberid')['othermemberid'].agg(list).to_pandas()\n",
    "        their_likes = {k: set(v) for k, v in their_likes.items()}\n",
    "        \n",
    "        label = \"FEMALES VIEWING MALES\"\n",
    "        opposite_label = \"male\"\n",
    "    \n",
    "    # Calculate total mutual matches in test set\n",
    "    total_mutual_matches_in_test = 0\n",
    "    for user_id in my_likes:\n",
    "        for other_id in my_likes[user_id]:\n",
    "            # Check if mutual\n",
    "            if user_id in their_likes.get(other_id, set()):\n",
    "                total_mutual_matches_in_test += 1\n",
    "    \n",
    "    # ⚡ KEEP ON GPU: Filter valid users on GPU\n",
    "    user_df_test = engine_test.user_df\n",
    "    valid_users_gpu = user_df_test[user_df_test['user_id'].isin(list(my_likes.keys()))]\n",
    "    test_users_valid = valid_users_gpu['user_id'].to_arrow().to_pylist()\n",
    "    \n",
    "    print(f\"Test users ({gender}) with held-out likes: {len(test_users_valid):,}\")\n",
    "    print(f\"Opposite gender users who liked someone: {len(their_likes):,}\")\n",
    "    print(f\"Total mutual matches in test set: {total_mutual_matches_in_test:,}\")\n",
    "    \n",
    "    if len(test_users_valid) == 0:\n",
    "        print(\"⚠️ No test users found\")\n",
    "        return None\n",
    "    \n",
    "    # Generate recommendations for ALL users\n",
    "    print(f\"Generating recommendations for all {len(test_users_valid):,} users...\")\n",
    "    recs_batch = engine_test.recommend_batch(test_users_valid, k=k)\n",
    "    \n",
    "    hits = 0\n",
    "    mutual_hits = 0\n",
    "    all_recs = []\n",
    "    mutual_matches = []\n",
    "    \n",
    "    for user_id in tqdm(test_users_valid, desc=f\"Evaluating {gender}\"):\n",
    "        # Extract user IDs from recommendations\n",
    "        recs = [rec[0] for rec in recs_batch[user_id]]\n",
    "        all_recs.extend(recs)\n",
    "        \n",
    "        # Get who this user liked in test set\n",
    "        actual_likes = my_likes.get(user_id, set())\n",
    "        recommended = set(recs)\n",
    "        \n",
    "        # One-sided hit (user liked someone we recommended)\n",
    "        if len(actual_likes & recommended) > 0:\n",
    "            hits += 1\n",
    "            \n",
    "            # Check for MUTUAL compatibility\n",
    "            for other_id in (actual_likes & recommended):\n",
    "                # Did the other person ALSO like this user in the test set?\n",
    "                if user_id in their_likes.get(other_id, set()):\n",
    "                    mutual_hits += 1\n",
    "                    mutual_matches.append((user_id, other_id))\n",
    "                    break  # Count once per user\n",
    "    \n",
    "    # Calculate metrics\n",
    "    hit_rate = hits / len(test_users_valid)\n",
    "    mutual_hit_rate = mutual_hits / len(test_users_valid)\n",
    "    personalization = len(set(all_recs)) / len(all_recs) if len(all_recs) > 0 else 0\n",
    "    recall_of_matches = mutual_hits / total_mutual_matches_in_test if total_mutual_matches_in_test > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"📊 HELD-OUT TEST SET EVALUATION (k={k}) - {label}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"One-Sided Hit Rate:    {hit_rate:.2%} ({hits:,}/{len(test_users_valid):,} users)\")\n",
    "    print(f\"   ↳ User liked someone we recommended\")\n",
    "    print(f\"\\nMUTUAL Match Rate:     {mutual_hit_rate:.2%} ({mutual_hits:,}/{len(test_users_valid):,} users)\")\n",
    "    print(f\"   ↳ Both users liked each other (TRUE compatibility!)\")\n",
    "    print(f\"\\nMatch Recall:          {recall_of_matches:.2%} ({mutual_hits:,}/{total_mutual_matches_in_test:,} matches)\")\n",
    "    print(f\"   ↳ Proportion of ALL mutual matches we found in top-{k}\")\n",
    "    print(f\"\\nPersonalization:       {personalization:.2%}\")\n",
    "    print(f\"Unique recs:           {len(set(all_recs)):,}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if mutual_hits > 0:\n",
    "        print(f\"\\n✅ Found {mutual_hits:,} mutual matches out of {total_mutual_matches_in_test:,} total in test set!\")\n",
    "        print(f\"💡 Match recall of {recall_of_matches:.1%} means we found {recall_of_matches:.1%} of all possible matches in top-{k}!\")\n",
    "    \n",
    "    return {\n",
    "        'gender': gender,\n",
    "        'test_users_valid': test_users_valid,\n",
    "        'all_recs': all_recs,\n",
    "        'hits': hits,\n",
    "        'mutual_hits': mutual_hits,\n",
    "        'mutual_matches': mutual_matches,\n",
    "        'hit_rate': hit_rate,\n",
    "        'mutual_hit_rate': mutual_hit_rate,\n",
    "        'personalization': personalization,\n",
    "        'total_mutual_matches_in_test': total_mutual_matches_in_test,\n",
    "        'recall_of_matches': recall_of_matches\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59d39a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_recommendation_coverage(engine, results_dict, opposite_gender='F'):\n",
    "    \"\"\"\n",
    "    Analyse which users are being recommended and correlate with popularity/engagement.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    engine : MatchingEngine\n",
    "        The trained recommendation engine\n",
    "    results_dict : dict\n",
    "        Results from evaluate_mutual_compatibility function\n",
    "    opposite_gender : str\n",
    "        'F' to analyse females being recommended (to males)\n",
    "        'M' to analyse males being recommended (to females)\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from collections import Counter\n",
    "    from scipy.stats import pearsonr, spearmanr\n",
    "    \n",
    "    all_recs = results_dict['all_recs']\n",
    "    test_users_valid = results_dict['test_users_valid']\n",
    "    \n",
    "    # Get all potential candidates of specified gender\n",
    "    user_df_test = engine.user_df\n",
    "    candidates = user_df_test[user_df_test.gender == opposite_gender].copy().to_pandas()\n",
    "    \n",
    "    # Count how many times each candidate was recommended\n",
    "    rec_counts_dict = Counter(all_recs)\n",
    "    candidates['times_recommended'] = candidates['user_id'].map(lambda x: rec_counts_dict.get(x, 0))\n",
    "    \n",
    "    # Get candidates who were NEVER recommended\n",
    "    never_recommended = candidates[candidates['times_recommended'] == 0]\n",
    "    recommended_users = candidates[candidates['times_recommended'] > 0]\n",
    "    \n",
    "    gender_label = \"Female\" if opposite_gender == 'F' else \"Male\"\n",
    "    \n",
    "    print(f\"\\n📊 RECOMMENDATION COVERAGE ANALYSIS ({gender_label} Users)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total {gender_label.lower()} users available: {len(candidates):,}\")\n",
    "    print(f\"{gender_label}s recommended at least once: {len(recommended_users):,}\")\n",
    "    print(f\"{gender_label}s NEVER recommended: {len(never_recommended):,} ({len(never_recommended)/len(candidates)*100:.1f}%)\")\n",
    "    \n",
    "    # Check if any users were actually recommended\n",
    "    if len(recommended_users) == 0:\n",
    "        print(f\"\\n⚠️  WARNING: No {gender_label.lower()}s were recommended in this evaluation!\")\n",
    "        return candidates, recommended_users, never_recommended\n",
    "    \n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Create scatter plots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # 1. Times Recommended vs elo_rating (Popularity)\n",
    "    axes[0].scatter(candidates['elo_rating'], candidates['times_recommended'], \n",
    "                    alpha=0.5, s=20, c=candidates['times_recommended'], cmap='viridis')\n",
    "    axes[0].set_xlabel('elo_rating Score (Popularity)', fontsize=12)\n",
    "    axes[0].set_ylabel('Times Recommended', fontsize=12)\n",
    "    axes[0].set_title(f'{gender_label} Recommendation Frequency vs Popularity Score', fontsize=14)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_xscale('log')\n",
    "    \n",
    "    # Add correlation\n",
    "    valid_mask = ~candidates['elo_rating'].isna() & ~candidates['times_recommended'].isna()\n",
    "    if valid_mask.sum() > 0:\n",
    "        pearson_corr, _ = pearsonr(candidates[valid_mask]['elo_rating'], \n",
    "                                    candidates[valid_mask]['times_recommended'])\n",
    "        spearman_corr, _ = spearmanr(candidates[valid_mask]['elo_rating'], \n",
    "                                      candidates[valid_mask]['times_recommended'])\n",
    "        axes[0].text(0.05, 0.95, f'Pearson: {pearson_corr:.3f}\\nSpearman: {spearman_corr:.3f}', \n",
    "                    transform=axes[0].transAxes, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # 2. Times Recommended vs Engagement Score\n",
    "    axes[1].scatter(candidates['engagement_score'], candidates['times_recommended'], \n",
    "                    alpha=0.5, s=20, c=candidates['times_recommended'], cmap='plasma')\n",
    "    axes[1].set_xlabel('Engagement Score', fontsize=12)\n",
    "    axes[1].set_ylabel('Times Recommended', fontsize=12)\n",
    "    axes[1].set_title(f'{gender_label} Recommendation Frequency vs Engagement Score', fontsize=14)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add correlation\n",
    "    valid_mask = ~candidates['engagement_score'].isna() & ~candidates['times_recommended'].isna()\n",
    "    if valid_mask.sum() > 0:\n",
    "        pearson_corr, _ = pearsonr(candidates[valid_mask]['engagement_score'], \n",
    "                                    candidates[valid_mask]['times_recommended'])\n",
    "        spearman_corr, _ = spearmanr(candidates[valid_mask]['engagement_score'], \n",
    "                                      candidates[valid_mask]['times_recommended'])\n",
    "        axes[1].text(0.05, 0.95, f'Pearson: {pearson_corr:.3f}\\nSpearman: {spearman_corr:.3f}', \n",
    "                    transform=axes[1].transAxes, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'recommendation_coverage_{opposite_gender}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Detailed stats on never-recommended users\n",
    "    if len(never_recommended) > 0:\n",
    "        print(f\"\\n📉 NEVER-RECOMMENDED {gender_label.upper()}S ANALYSIS:\")\n",
    "        print(f\"   • Avg elo_rating: {never_recommended['elo_rating'].mean():.6f} (vs {candidates['elo_rating'].mean():.6f} overall)\")\n",
    "        print(f\"   • Avg Engagement: {never_recommended['engagement_score'].mean():.2f} (vs {candidates['engagement_score'].mean():.2f} overall)\")\n",
    "        print(f\"   • League distribution:\")\n",
    "        for league in ['Bronze', 'Silver', 'Gold', 'Platinum', 'Diamond']:\n",
    "            count = len(never_recommended[never_recommended['league'] == league])\n",
    "            pct = count / len(never_recommended) * 100 if len(never_recommended) > 0 else 0\n",
    "            print(f\"      - {league}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Compare recommended vs never-recommended users\n",
    "    print(f\"\\n📊 COMPARISON: Recommended vs Never-Recommended {gender_label}s\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    print(f\"\\n{'Metric':<25} {'Recommended':<20} {'Never Recommended':<20}\")\n",
    "    print(f\"{'-'*65}\")\n",
    "    print(f\"{'Count':<25} {len(recommended_users):<20} {len(never_recommended):<20}\")\n",
    "    print(f\"{'Avg elo_rating':<25} {recommended_users['elo_rating'].mean():<20.6f} {never_recommended['elo_rating'].mean():<20.6f}\")\n",
    "    print(f\"{'Median elo_rating':<25} {recommended_users['elo_rating'].median():<20.6f} {never_recommended['elo_rating'].median():<20.6f}\")\n",
    "    print(f\"{'Avg Engagement':<25} {recommended_users['engagement_score'].mean():<20.2f} {never_recommended['engagement_score'].mean():<20.2f}\")\n",
    "    print(f\"{'Median Engagement':<25} {recommended_users['engagement_score'].median():<20.2f} {never_recommended['engagement_score'].median():<20.2f}\")\n",
    "    \n",
    "    return candidates, recommended_users, never_recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe92774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluating MUTUAL compatibility - M users viewing females...\n",
      "\n",
      "Test users (M) with held-out likes: 19,123\n",
      "Opposite gender users who liked someone: 4,725\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 19,123 users...\n",
      "Test users (M) with held-out likes: 19,123\n",
      "Opposite gender users who liked someone: 4,725\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 19,123 users...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluating MUTUAL compatibility - M users viewing females...\n",
      "\n",
      "Test users (M) with held-out likes: 19,123\n",
      "Opposite gender users who liked someone: 4,725\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 19,123 users...\n",
      "Test users (M) with held-out likes: 19,123\n",
      "Opposite gender users who liked someone: 4,725\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 19,123 users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating M: 100%|██████████| 19123/19123 [00:00<00:00, 127257.82it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluating MUTUAL compatibility - M users viewing females...\n",
      "\n",
      "Test users (M) with held-out likes: 19,123\n",
      "Opposite gender users who liked someone: 4,725\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 19,123 users...\n",
      "Test users (M) with held-out likes: 19,123\n",
      "Opposite gender users who liked someone: 4,725\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 19,123 users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating M: 100%|██████████| 19123/19123 [00:00<00:00, 127257.82it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "📊 HELD-OUT TEST SET EVALUATION (k=100) - MALES VIEWING FEMALES\n",
      "======================================================================\n",
      "One-Sided Hit Rate:    42.75% (8,175/19,123 users)\n",
      "   ↳ User liked someone we recommended\n",
      "\n",
      "MUTUAL Match Rate:     1.01% (194/19,123 users)\n",
      "   ↳ Both users liked each other (TRUE compatibility!)\n",
      "\n",
      "Match Recall:          5.22% (194/3,714 matches)\n",
      "   ↳ Proportion of ALL mutual matches we found in top-100\n",
      "\n",
      "Personalization:       1.30%\n",
      "Unique recs:           22,242\n",
      "======================================================================\n",
      "\n",
      "✅ Found 194 mutual matches out of 3,714 total in test set!\n",
      "💡 Match recall of 5.2% means we found 5.2% of all possible matches in top-100!\n"
     ]
    }
   ],
   "source": [
    "# Evaluate ALL males viewing females (no sampling)\n",
    "results_males = evaluate_mutual_compatibility(engine_test, test_data, gender='M', k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d8085dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluating MUTUAL compatibility - F users viewing males...\n",
      "\n",
      "Test users (F) with held-out likes: 4,725\n",
      "Opposite gender users who liked someone: 19,123\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 4,725 users...\n",
      "Test users (F) with held-out likes: 4,725\n",
      "Opposite gender users who liked someone: 19,123\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 4,725 users...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluating MUTUAL compatibility - F users viewing males...\n",
      "\n",
      "Test users (F) with held-out likes: 4,725\n",
      "Opposite gender users who liked someone: 19,123\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 4,725 users...\n",
      "Test users (F) with held-out likes: 4,725\n",
      "Opposite gender users who liked someone: 19,123\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 4,725 users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating F: 100%|██████████| 4725/4725 [00:00<00:00, 78964.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluating MUTUAL compatibility - F users viewing males...\n",
      "\n",
      "Test users (F) with held-out likes: 4,725\n",
      "Opposite gender users who liked someone: 19,123\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 4,725 users...\n",
      "Test users (F) with held-out likes: 4,725\n",
      "Opposite gender users who liked someone: 19,123\n",
      "Total mutual matches in test set: 3,714\n",
      "Generating recommendations for all 4,725 users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating F: 100%|██████████| 4725/4725 [00:00<00:00, 78964.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "📊 HELD-OUT TEST SET EVALUATION (k=100) - FEMALES VIEWING MALES\n",
      "======================================================================\n",
      "One-Sided Hit Rate:    2.96% (140/4,725 users)\n",
      "   ↳ User liked someone we recommended\n",
      "\n",
      "MUTUAL Match Rate:     0.99% (47/4,725 users)\n",
      "   ↳ Both users liked each other (TRUE compatibility!)\n",
      "\n",
      "Match Recall:          1.27% (47/3,714 matches)\n",
      "   ↳ Proportion of ALL mutual matches we found in top-100\n",
      "\n",
      "Personalization:       3.36%\n",
      "Unique recs:           13,087\n",
      "======================================================================\n",
      "\n",
      "✅ Found 47 mutual matches out of 3,714 total in test set!\n",
      "💡 Match recall of 1.3% means we found 1.3% of all possible matches in top-100!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate females viewing males\n",
    "results_females = evaluate_mutual_compatibility(engine_test, test_data, gender='F', k=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ee33a9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99df6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_case_statistics(target_id: int,\n",
    "                         interactions: \"cudf.DataFrame\",\n",
    "                         engine,\n",
    "                         rec_k: int = 30) -> None:\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    print(f\"### Test case statistics for user {target_id} ###\\n\")\n",
    "\n",
    "    decider_df = interactions[interactions[\"decidermemberid\"] == target_id]\n",
    "    total_decisions = len(decider_df)\n",
    "    like_rate = float(decider_df[\"like\"].mean()) if total_decisions else 0.0\n",
    "\n",
    "    likes_given = decider_df[decider_df[\"like\"] == 1]\n",
    "    likes_received = interactions[\n",
    "        (interactions[\"othermemberid\"] == target_id) & (interactions[\"like\"] == 1)\n",
    "    ]\n",
    "\n",
    "    matches = likes_given.merge(\n",
    "        likes_received,\n",
    "        left_on=\"othermemberid\",\n",
    "        right_on=\"decidermemberid\",\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    match_rate = len(matches) / total_decisions if total_decisions else 0.0\n",
    "    match_rate_given_likes = len(matches) / len(likes_given) if len(likes_given) else 0.0\n",
    "\n",
    "    print(f\"Like rate: {like_rate:.2%}\")\n",
    "    print(f\"Match rate: {match_rate:.2%}\")\n",
    "    print(f\"Match rate given likes: {match_rate_given_likes:.2%}\\n\")\n",
    "\n",
    "    recs = engine.recommend_batch([target_id], k=rec_k).get(target_id, [])\n",
    "    if not recs:\n",
    "        print(\"No recommendations available.\\n\")\n",
    "        return\n",
    "\n",
    "    rec_df = pd.DataFrame(recs, columns=[\"candidate_id\", \"score\"])\n",
    "    liked_ids = set(likes_given[\"othermemberid\"].to_pandas().tolist())\n",
    "    rec_df[\"label\"] = rec_df[\"candidate_id\"].apply(lambda cid: 1 if cid in liked_ids else 0)\n",
    "    \n",
    "    # 🔍 DIAGNOSTIC INFO\n",
    "    print(f\"DEBUG INFO:\")\n",
    "    print(f\"  Total people user liked in dataset: {len(liked_ids)}\")\n",
    "    print(f\"  People with label=1 in top-{rec_k}: {rec_df['label'].sum()}\")\n",
    "    print(f\"  Hit rate in top-{rec_k}: {rec_df['label'].sum() / len(liked_ids) * 100:.1f}%\\n\")\n",
    "    \n",
    "    print(rec_df.nlargest(5, \"score\"), end=\"\\n\\n\")\n",
    "\n",
    "    dcg = 0.0\n",
    "    for rank, rel in enumerate(rec_df.nlargest(rec_k, \"score\")[\"label\"], start=1):\n",
    "        dcg += (2 ** rel - 1) / np.log2(rank + 1)\n",
    "\n",
    "    ideal_labels = rec_df.nlargest(rec_k, \"label\")[\"label\"]\n",
    "    idcg = 0.0\n",
    "    for rank, rel in enumerate(ideal_labels, start=1):\n",
    "        idcg += (2 ** rel - 1) / np.log2(rank + 1)\n",
    "\n",
    "    ndcg_30 = dcg / idcg if idcg > 0 else 0.0\n",
    "    print(f\"NDCG@{rec_k} for user {target_id}: {ndcg_30:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b8efc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Test case statistics for user 1142425 ###\n",
      "\n",
      "Like rate: 6.25%\n",
      "Match rate: 4.17%\n",
      "Match rate given likes: 66.67%\n",
      "\n",
      "DEBUG INFO:\n",
      "  Total people user liked in dataset: 6\n",
      "  People with label=1 in top-30: 1\n",
      "  Hit rate in top-30: 16.7%\n",
      "\n",
      "   candidate_id     score  label\n",
      "0       3832057  0.767458      0\n",
      "1       2978402  0.603261      0\n",
      "2        259471  0.595033      0\n",
      "3        855168  0.497982      0\n",
      "4       2356285  0.441220      0\n",
      "\n",
      "NDCG@30 for user 1142425: 0.2080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_case_statistics(1142425, test_data, engine_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdeb1b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Test case statistics for user 336132 ###\n",
      "\n",
      "Like rate: 28.57%\n",
      "Match rate: 2.38%\n",
      "Match rate given likes: 8.33%\n",
      "\n",
      "DEBUG INFO:\n",
      "  Total people user liked in dataset: 12\n",
      "  People with label=1 in top-30: 0\n",
      "  Hit rate in top-30: 0.0%\n",
      "\n",
      "   candidate_id     score  label\n",
      "0       3866079  0.557231      0\n",
      "1        681097  0.476687      0\n",
      "2       3861867  0.451380      0\n",
      "3        497066  0.451015      0\n",
      "4       2848163  0.404130      0\n",
      "\n",
      "NDCG@30 for user 336132: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_case_statistics(336132, test_data, engine_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3637cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1b6ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, log_loss\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def summarize_classification_pairs(pairs_df):\n",
    "    \"\"\"Add calibrated probabilities, print metrics, and return summary stats.\"\"\"\n",
    "    if pairs_df is None or len(pairs_df) == 0:\n",
    "        print(\"⚠️ No pairs generated!\")\n",
    "        return None, {}\n",
    "\n",
    "    pairs_df = pairs_df.copy()\n",
    "    scores = pairs_df['score'].values\n",
    "    z = (scores - scores.mean()) / (scores.std() + 1e-12)  # standardize\n",
    "    pairs_df['proba'] = expit(z)  # sigmoid -> (0, 1)\n",
    "\n",
    "    metrics = {\n",
    "        'num_pairs': int(len(pairs_df)),\n",
    "        'positive_pairs': int(pairs_df['label'].sum()),\n",
    "        'negative_pairs': int((1 - pairs_df['label']).sum()),\n",
    "        'positive_rate': float(pairs_df['label'].mean()),\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        metrics['auc_micro'] = float(roc_auc_score(pairs_df['label'], pairs_df['score']))\n",
    "        metrics['ap_micro'] = float(average_precision_score(pairs_df['label'], pairs_df['score']))\n",
    "        metrics['brier'] = float(brier_score_loss(pairs_df['label'], pairs_df['proba']))\n",
    "        metrics['logloss'] = float(log_loss(pairs_df['label'], pairs_df['proba']))\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error computing metrics: {e}\")\n",
    "        print(f\"Label distribution: {pairs_df['label'].value_counts()}\")\n",
    "        return pairs_df, metrics\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"### ML (ALS RECOMMENDER) PERFORMANCE ON TEST SET ###\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total pairs evaluated:             {metrics['num_pairs']:,}\")\n",
    "    print(f\"Positive pairs (likes):            {metrics['positive_pairs']:,} ({metrics['positive_rate']:.2%})\")\n",
    "    print(f\"Negative pairs (no like):          {metrics['negative_pairs']:,}\")\n",
    "    print(f\"\\nMicro ROC AUC:                     {metrics['auc_micro']:.4f}\")\n",
    "    print(f\"Micro Average Precision (PR-AUC):  {metrics['ap_micro']:.4f}\")\n",
    "    print(f\"Brier score:                       {metrics['brier']:.4f}\")\n",
    "    print(f\"Log loss:                          {metrics['logloss']:.4f}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    return pairs_df, metrics\n",
    "\n",
    "def evaluate_classification_metrics(engine, test_data, sample_size=None, k=100):\n",
    "    \"\"\"\n",
    "    Evaluate classification metrics (AUC, AP, Brier, Log Loss) on test set.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    engine : MatchingEngine\n",
    "        The trained recommendation engine\n",
    "    test_data : cudf.DataFrame\n",
    "        Test set interactions\n",
    "    sample_size : int, optional\n",
    "        Number of users to sample for evaluation (None = all users)\n",
    "    k : int, optional\n",
    "        Number of recommendations generated per user\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple[pd.DataFrame | None, dict]: pairs with labels/scores and summary metrics\n",
    "    \"\"\"\n",
    "    print(\"\\n📊 CLASSIFICATION METRICS EVALUATION ON TEST SET\\n\")\n",
    "\n",
    "    test_users = test_data['decidermemberid'].unique().to_pandas().tolist()\n",
    "\n",
    "    if sample_size and sample_size < len(test_users):\n",
    "        test_users = np.random.choice(test_users, size=sample_size, replace=False).tolist()\n",
    "        print(f\"Sampled {sample_size:,} users from test set\")\n",
    "    else:\n",
    "        print(f\"Evaluating all {len(test_users):,} users in test set\")\n",
    "\n",
    "    test_likes = test_data[test_data['like'] == 1][['decidermemberid', 'othermemberid']]\n",
    "    ground_truth = test_likes.groupby('decidermemberid')['othermemberid'].agg(list).to_pandas()\n",
    "    ground_truth = {k: set(v) for k, v in ground_truth.items()}\n",
    "\n",
    "    print(f\"Generating recommendations for {len(test_users):,} users...\")\n",
    "    recs_batch = engine.recommend_batch(test_users, k=k)\n",
    "\n",
    "    pairs_list = []\n",
    "    for user_id in tqdm(test_users, desc=\"Building pairs\"):\n",
    "        recs = recs_batch.get(user_id, [])\n",
    "        for candidate_id, score in recs:\n",
    "            label = 1 if candidate_id in ground_truth.get(user_id, set()) else 0\n",
    "            pairs_list.append({\n",
    "                'user': user_id,\n",
    "                'item': candidate_id,\n",
    "                'score': score,\n",
    "                'label': label\n",
    "            })\n",
    "\n",
    "    if not pairs_list:\n",
    "        print(\"⚠️ No pairs generated!\")\n",
    "        return None, {}\n",
    "\n",
    "    pairs_df = pd.DataFrame(pairs_list)\n",
    "    return summarize_classification_pairs(pairs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd39f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "impressions_df = (\n",
    "    test_data[['decidermemberid', 'othermemberid']]\n",
    "    .rename(columns={'decidermemberid': 'user', 'othermemberid': 'item'})\n",
    "    .drop_duplicates()\n",
    "    .to_pandas()\n",
    " )\n",
    "\n",
    "likes_by_user = (\n",
    "    test_data[test_data['like'] == 1][['decidermemberid', 'othermemberid']]\n",
    "    .rename(columns={'decidermemberid': 'user', 'othermemberid': 'item'})\n",
    "    .groupby('user')['item']\n",
    "    .agg(list)\n",
    "    .to_pandas()\n",
    "    .apply(set)\n",
    "    .to_dict()\n",
    " )\n",
    "\n",
    "def evaluate_classification_metrics_seen_only(pairs_df):\n",
    "    \"\"\"Restrict evaluation to impressions the user actually saw under the logged policy.\"\"\"\n",
    "    if pairs_df is None or len(pairs_df) == 0:\n",
    "        print('⚠️ No recommendation pairs supplied.')\n",
    "        return None, {}\n",
    "\n",
    "    filtered_pairs = pairs_df.merge(impressions_df, on=['user', 'item'], how='inner')\n",
    "\n",
    "    if filtered_pairs.empty:\n",
    "        print('⚠️ No recommendations overlapped with held-out impressions.')\n",
    "        return None, {}\n",
    "\n",
    "    return summarize_classification_pairs(filtered_pairs)\n",
    "\n",
    "def matched_hits_at_k(pairs_df, k=100):\n",
    "    \"\"\"Compute off-policy Matched Hits@K (precision-style metric) using only seen impressions.\"\"\"\n",
    "    if pairs_df is None or len(pairs_df) == 0:\n",
    "        print('⚠️ No recommendation pairs supplied.')\n",
    "        return 0.0, pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    ranked = pairs_df.sort_values(['user', 'score'], ascending=[True, False])\n",
    "    topk = ranked.groupby('user', as_index=False).head(k)\n",
    "\n",
    "    if topk.empty:\n",
    "        print('⚠️ No recommendations available for matched hits calculation.')\n",
    "        return 0.0, topk, pd.DataFrame()\n",
    "\n",
    "    seen_topk = topk.merge(impressions_df, on=['user', 'item'], how='inner')\n",
    "\n",
    "    if seen_topk.empty:\n",
    "        print('⚠️ None of the recommended pairs were observed under the logged policy.')\n",
    "        return 0.0, seen_topk, pd.DataFrame()\n",
    "\n",
    "    seen_topk['matched_like'] = seen_topk.apply(\n",
    "        lambda row: 1 if row['item'] in likes_by_user.get(row['user'], set()) else 0, axis=1\n",
    "    )\n",
    "\n",
    "    per_user = (\n",
    "        seen_topk.groupby('user')['matched_like']\n",
    "        .agg(['sum', 'count'])\n",
    "        .rename(columns={'sum': 'matched_likes', 'count': 'items_returned'})\n",
    "    )\n",
    "\n",
    "    num_users = len(per_user)\n",
    "    if num_users == 0:\n",
    "        print('⚠️ No users with seen recommendations for matched hits calculation.')\n",
    "        return 0.0, seen_topk, per_user\n",
    "\n",
    "    total_items_returned = per_user['items_returned'].sum()\n",
    "    matched_hits = per_user['matched_likes'].sum() / total_items_returned if total_items_returned else 0.0\n",
    "    per_user['matched_hits_at_k'] = per_user['matched_likes'] / per_user['items_returned']\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"### OFF-POLICY MATCHED HITS@K (SEEN IMPRESSIONS) ###\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Users evaluated:                  {num_users:,}\")\n",
    "    print(f\"Total seen recommendations:       {total_items_returned:,}\")\n",
    "    print(f\"Matched Hits@{k} (micro):          {matched_hits:.4f}\")\n",
    "    print(f\"Median per-user matched hits:     {per_user['matched_hits_at_k'].median():.4f}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    return matched_hits, seen_topk, per_user\n",
    "\n",
    "def matched_hits_for_user(engine, user_id, k=100):\n",
    "    \"\"\"Compute Matched Hits@K (micro) for a single user over seen impressions.\"\"\"\n",
    "    recs = engine.recommend_for_user(user_id, k=k) or []\n",
    "    if not recs:\n",
    "        print(f\"⚠️ No recommendations available for user {user_id}.\")\n",
    "        return 0.0\n",
    "\n",
    "    rec_df = pd.DataFrame(recs, columns=['item', 'score'])\n",
    "    seen = impressions_df[impressions_df['user'] == user_id]\n",
    "\n",
    "    if seen.empty:\n",
    "        print(f\"⚠️ User {user_id} has no logged impressions in the test set.\")\n",
    "        return 0.0\n",
    "\n",
    "    seen_recs = rec_df.merge(seen, on='item', how='inner')\n",
    "\n",
    "    if seen_recs.empty:\n",
    "        print(f\"⚠️ None of the top-{k} recommendations for user {user_id} were logged impressions.\")\n",
    "        return 0.0\n",
    "\n",
    "    liked_items = likes_by_user.get(user_id, set())\n",
    "    seen_recs['matched_like'] = seen_recs['item'].isin(liked_items).astype(int)\n",
    "\n",
    "    hits = int(seen_recs['matched_like'].sum())\n",
    "    total = int(len(seen_recs))\n",
    "\n",
    "    rate = hits / total if total else 0.0\n",
    "\n",
    "    print(f\"User {user_id} – Matched Hits@{k} (micro): {rate:.4f} ({hits}/{total} seen recommendations)\")\n",
    "    return rate\n",
    "\n",
    "def logged_hits_for_user(interactions, user_id):\n",
    "    \"\"\"Compute historical hit rate for a user from the logged policy.\"\"\"\n",
    "    user_history = interactions[interactions['decidermemberid'] == user_id][['othermemberid', 'like']]\n",
    "\n",
    "    if len(user_history) == 0:\n",
    "        print(f\"⚠️ No logged impressions for user {user_id} in this split.\")\n",
    "        return 0.0\n",
    "\n",
    "    impressions = int(len(user_history))\n",
    "    likes = int(user_history['like'].sum())\n",
    "    rate = likes / impressions if impressions else 0.0\n",
    "\n",
    "    print(f\"User {user_id} – Logged policy hit rate: {rate:.4f} ({likes}/{impressions} impressions)\")\n",
    "    return rate\n",
    "\n",
    "def logged_policy_matched_hits(interactions):\n",
    "    \"\"\"Compute matched hit statistics for the historical logged policy.\"\"\"\n",
    "    df = interactions[['decidermemberid', 'othermemberid', 'like']].to_pandas()\n",
    "\n",
    "    if df.empty:\n",
    "        print('⚠️ Interaction data is empty.')\n",
    "        return 0.0, pd.DataFrame()\n",
    "\n",
    "    per_user = (\n",
    "        df.groupby('decidermemberid')\n",
    "        .agg(impressions=('othermemberid', 'count'), matched_likes=('like', 'sum'))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    per_user['matched_hits_rate'] = per_user['matched_likes'] / per_user['impressions']\n",
    "\n",
    "    total_impressions = per_user['impressions'].sum()\n",
    "    total_matched_likes = per_user['matched_likes'].sum()\n",
    "\n",
    "    micro_rate = total_matched_likes / total_impressions if total_impressions else 0.0\n",
    "    median_rate = per_user['matched_hits_rate'].median() if not per_user.empty else 0.0\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"### LOGGED POLICY MATCHED HITS ###\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Users evaluated:                  {len(per_user):,}\")\n",
    "    print(f\"Total logged impressions:         {total_impressions:,}\")\n",
    "    print(f\"Total logged likes (matches):     {int(total_matched_likes):,}\")\n",
    "    print(f\"Matched Hits (micro):             {micro_rate:.4f}\")\n",
    "    print(f\"Median per-user matched hits:     {median_rate:.4f}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    return micro_rate, per_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36463162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring logged impressions...\n",
      "⚠️ Assigning fallback score to 140,366 impressions with unsupported gender pairing.\n",
      "⚠️ Assigning fallback score to 140,366 impressions with unsupported gender pairing.\n",
      "Evaluating classification metrics on seen impressions...\n",
      "Evaluating classification metrics on seen impressions...\n",
      "\n",
      "======================================================================\n",
      "### ML (ALS RECOMMENDER) PERFORMANCE ON TEST SET ###\n",
      "======================================================================\n",
      "Total pairs evaluated:             1,922,365\n",
      "Positive pairs (likes):            690,014 (35.89%)\n",
      "Negative pairs (no like):          1,232,351\n",
      "\n",
      "Micro ROC AUC:                     0.7089\n",
      "Micro Average Precision (PR-AUC):  0.6058\n",
      "Brier score:                       0.2620\n",
      "Log loss:                          0.7419\n",
      "======================================================================\n",
      "\n",
      "Computing matched hits@100 for recommendations (seen impressions only)...\n",
      "\n",
      "======================================================================\n",
      "### ML (ALS RECOMMENDER) PERFORMANCE ON TEST SET ###\n",
      "======================================================================\n",
      "Total pairs evaluated:             1,922,365\n",
      "Positive pairs (likes):            690,014 (35.89%)\n",
      "Negative pairs (no like):          1,232,351\n",
      "\n",
      "Micro ROC AUC:                     0.7089\n",
      "Micro Average Precision (PR-AUC):  0.6058\n",
      "Brier score:                       0.2620\n",
      "Log loss:                          0.7419\n",
      "======================================================================\n",
      "\n",
      "Computing matched hits@100 for recommendations (seen impressions only)...\n",
      "\n",
      "======================================================================\n",
      "### OFF-POLICY MATCHED HITS@K (SEEN IMPRESSIONS) ###\n",
      "======================================================================\n",
      "Users evaluated:                  30,327\n",
      "Total recommendations scored:      1,127,029\n",
      "Total matched likes (hits):       417,973\n",
      "Matched Hits@100 (micro):         0.3709\n",
      "Median per-user matched hits:     0.2941\n",
      "======================================================================\n",
      "\n",
      "Computing logged policy matched hits for comparison...\n",
      "\n",
      "======================================================================\n",
      "### LOGGED POLICY MATCHED HITS ###\n",
      "======================================================================\n",
      "Users evaluated:                  30,327\n",
      "Total logged impressions:         1,965,578\n",
      "Total logged likes (matches):     699,679\n",
      "Matched Hits (micro):             0.3560\n",
      "Median per-user matched hits:     0.2857\n",
      "======================================================================\n",
      "\n",
      "Computing NDCG@100 from scored impressions...\n",
      "\n",
      "======================================================================\n",
      "### OFF-POLICY MATCHED HITS@K (SEEN IMPRESSIONS) ###\n",
      "======================================================================\n",
      "Users evaluated:                  30,327\n",
      "Total recommendations scored:      1,127,029\n",
      "Total matched likes (hits):       417,973\n",
      "Matched Hits@100 (micro):         0.3709\n",
      "Median per-user matched hits:     0.2941\n",
      "======================================================================\n",
      "\n",
      "Computing logged policy matched hits for comparison...\n",
      "\n",
      "======================================================================\n",
      "### LOGGED POLICY MATCHED HITS ###\n",
      "======================================================================\n",
      "Users evaluated:                  30,327\n",
      "Total logged impressions:         1,965,578\n",
      "Total logged likes (matches):     699,679\n",
      "Matched Hits (micro):             0.3560\n",
      "Median per-user matched hits:     0.2857\n",
      "======================================================================\n",
      "\n",
      "Computing NDCG@100 from scored impressions...\n",
      "\n",
      "======================================================================\n",
      "### OFF-POLICY NDCG@K (LOGGED IMPRESSIONS) ###\n",
      "======================================================================\n",
      "Users evaluated:                  30,327\n",
      "NDCG@100 (micro):                 0.8653\n",
      "Median per-user NDCG:            0.7328\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "### OFF-POLICY NDCG@K (LOGGED IMPRESSIONS) ###\n",
      "======================================================================\n",
      "Users evaluated:                  30,327\n",
      "NDCG@100 (micro):                 0.8653\n",
      "Median per-user NDCG:            0.7328\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compare_old_new_recommendations(user_id, interactions, engine, k=100):\n",
    "    \"\"\"Return recent logged impressions and fresh recommendations for a user.\"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    user_history = (\n",
    "        interactions[interactions['decidermemberid'] == user_id]\n",
    "        .sort_values('timestamp', ascending=False)\n",
    "        [['timestamp', 'othermemberid', 'like']]\n",
    "        .to_pandas()\n",
    "    )\n",
    "\n",
    "    if user_history.empty:\n",
    "        print(f\"⚠️ No logged impressions found for user {user_id}.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    user_history = user_history.drop_duplicates(subset='othermemberid', keep='first')\n",
    "    user_history = user_history.rename(columns={'othermemberid': 'candidate_id', 'like': 'liked'})\n",
    "    user_history['liked'] = user_history['liked'].astype(int)\n",
    "\n",
    "    recent_logged = user_history.head(k).copy()\n",
    "\n",
    "    new_recs = engine.recommend_for_user(user_id, k=k) or []\n",
    "    if not new_recs:\n",
    "        print(f\"⚠️ Recommender returned no candidates for user {user_id}.\")\n",
    "        return recent_logged, pd.DataFrame()\n",
    "\n",
    "    new_df = pd.DataFrame(new_recs, columns=['candidate_id', 'score'])\n",
    "    new_df['seen_before'] = new_df['candidate_id'].isin(user_history['candidate_id'])\n",
    "    new_df['liked_before'] = new_df['candidate_id'].isin(user_history[user_history['liked'] == 1]['candidate_id'])\n",
    "\n",
    "    return recent_logged, new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6d64c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'User 268553 – recent logged impressions (liked only)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8077960</th>\n",
       "      <td>2021-01-04 23:50:00</td>\n",
       "      <td>1890123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510021</th>\n",
       "      <td>2021-01-04 23:49:56</td>\n",
       "      <td>3204604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9523742</th>\n",
       "      <td>2021-01-04 23:49:53</td>\n",
       "      <td>1643022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732380</th>\n",
       "      <td>2021-01-04 23:49:51</td>\n",
       "      <td>3825592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9589743</th>\n",
       "      <td>2021-01-04 23:49:50</td>\n",
       "      <td>680198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9821300</th>\n",
       "      <td>2021-01-04 23:49:47</td>\n",
       "      <td>1415704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3512927</th>\n",
       "      <td>2021-01-04 23:49:43</td>\n",
       "      <td>107142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8465051</th>\n",
       "      <td>2021-01-04 23:49:17</td>\n",
       "      <td>2793679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113628</th>\n",
       "      <td>2021-01-04 23:49:05</td>\n",
       "      <td>531340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758817</th>\n",
       "      <td>2021-01-04 23:42:18</td>\n",
       "      <td>981466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532510</th>\n",
       "      <td>2021-01-04 23:28:43</td>\n",
       "      <td>683003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626153</th>\n",
       "      <td>2021-01-04 23:28:36</td>\n",
       "      <td>1269010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512977</th>\n",
       "      <td>2021-01-04 23:28:34</td>\n",
       "      <td>1955273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8076881</th>\n",
       "      <td>2021-01-04 23:28:25</td>\n",
       "      <td>247457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557910</th>\n",
       "      <td>2021-01-04 23:28:24</td>\n",
       "      <td>3190271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8085602</th>\n",
       "      <td>2021-01-04 23:28:22</td>\n",
       "      <td>509739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640201</th>\n",
       "      <td>2021-01-04 23:28:20</td>\n",
       "      <td>123632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819908</th>\n",
       "      <td>2021-01-04 23:28:13</td>\n",
       "      <td>2285135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881326</th>\n",
       "      <td>2021-01-04 23:27:38</td>\n",
       "      <td>3268149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477194</th>\n",
       "      <td>2021-01-04 23:27:35</td>\n",
       "      <td>1480722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728033</th>\n",
       "      <td>2021-01-04 23:27:25</td>\n",
       "      <td>266061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779455</th>\n",
       "      <td>2021-01-04 23:27:24</td>\n",
       "      <td>687718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9146270</th>\n",
       "      <td>2021-01-04 23:27:23</td>\n",
       "      <td>965911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8124452</th>\n",
       "      <td>2021-01-04 23:27:18</td>\n",
       "      <td>172965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8463678</th>\n",
       "      <td>2021-01-04 23:20:27</td>\n",
       "      <td>1920148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150459</th>\n",
       "      <td>2021-01-04 23:20:00</td>\n",
       "      <td>376149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  candidate_id  liked\n",
       "8077960  2021-01-04 23:50:00       1890123      1\n",
       "9510021  2021-01-04 23:49:56       3204604      1\n",
       "9523742  2021-01-04 23:49:53       1643022      1\n",
       "5732380  2021-01-04 23:49:51       3825592      1\n",
       "9589743  2021-01-04 23:49:50        680198      1\n",
       "9821300  2021-01-04 23:49:47       1415704      1\n",
       "3512927  2021-01-04 23:49:43        107142      1\n",
       "8465051  2021-01-04 23:49:17       2793679      1\n",
       "8113628  2021-01-04 23:49:05        531340      1\n",
       "3758817  2021-01-04 23:42:18        981466      1\n",
       "5532510  2021-01-04 23:28:43        683003      1\n",
       "3626153  2021-01-04 23:28:36       1269010      1\n",
       "8512977  2021-01-04 23:28:34       1955273      1\n",
       "8076881  2021-01-04 23:28:25        247457      1\n",
       "3557910  2021-01-04 23:28:24       3190271      1\n",
       "8085602  2021-01-04 23:28:22        509739      1\n",
       "5640201  2021-01-04 23:28:20        123632      1\n",
       "9819908  2021-01-04 23:28:13       2285135      1\n",
       "3881326  2021-01-04 23:27:38       3268149      1\n",
       "3477194  2021-01-04 23:27:35       1480722      1\n",
       "7728033  2021-01-04 23:27:25        266061      1\n",
       "3779455  2021-01-04 23:27:24        687718      1\n",
       "9146270  2021-01-04 23:27:23        965911      1\n",
       "8124452  2021-01-04 23:27:18        172965      1\n",
       "8463678  2021-01-04 23:20:27       1920148      1\n",
       "8150459  2021-01-04 23:20:00        376149      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 268553 – Logged policy hit rate: 0.4230 (217/513 impressions)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'User 268553 – new recommendations (seen matches highlighted)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'User 268553 – recent logged impressions (liked only)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8077960</th>\n",
       "      <td>2021-01-04 23:50:00</td>\n",
       "      <td>1890123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510021</th>\n",
       "      <td>2021-01-04 23:49:56</td>\n",
       "      <td>3204604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9523742</th>\n",
       "      <td>2021-01-04 23:49:53</td>\n",
       "      <td>1643022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732380</th>\n",
       "      <td>2021-01-04 23:49:51</td>\n",
       "      <td>3825592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9589743</th>\n",
       "      <td>2021-01-04 23:49:50</td>\n",
       "      <td>680198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9821300</th>\n",
       "      <td>2021-01-04 23:49:47</td>\n",
       "      <td>1415704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3512927</th>\n",
       "      <td>2021-01-04 23:49:43</td>\n",
       "      <td>107142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8465051</th>\n",
       "      <td>2021-01-04 23:49:17</td>\n",
       "      <td>2793679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113628</th>\n",
       "      <td>2021-01-04 23:49:05</td>\n",
       "      <td>531340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758817</th>\n",
       "      <td>2021-01-04 23:42:18</td>\n",
       "      <td>981466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532510</th>\n",
       "      <td>2021-01-04 23:28:43</td>\n",
       "      <td>683003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626153</th>\n",
       "      <td>2021-01-04 23:28:36</td>\n",
       "      <td>1269010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512977</th>\n",
       "      <td>2021-01-04 23:28:34</td>\n",
       "      <td>1955273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8076881</th>\n",
       "      <td>2021-01-04 23:28:25</td>\n",
       "      <td>247457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557910</th>\n",
       "      <td>2021-01-04 23:28:24</td>\n",
       "      <td>3190271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8085602</th>\n",
       "      <td>2021-01-04 23:28:22</td>\n",
       "      <td>509739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640201</th>\n",
       "      <td>2021-01-04 23:28:20</td>\n",
       "      <td>123632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819908</th>\n",
       "      <td>2021-01-04 23:28:13</td>\n",
       "      <td>2285135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881326</th>\n",
       "      <td>2021-01-04 23:27:38</td>\n",
       "      <td>3268149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477194</th>\n",
       "      <td>2021-01-04 23:27:35</td>\n",
       "      <td>1480722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728033</th>\n",
       "      <td>2021-01-04 23:27:25</td>\n",
       "      <td>266061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779455</th>\n",
       "      <td>2021-01-04 23:27:24</td>\n",
       "      <td>687718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9146270</th>\n",
       "      <td>2021-01-04 23:27:23</td>\n",
       "      <td>965911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8124452</th>\n",
       "      <td>2021-01-04 23:27:18</td>\n",
       "      <td>172965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8463678</th>\n",
       "      <td>2021-01-04 23:20:27</td>\n",
       "      <td>1920148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150459</th>\n",
       "      <td>2021-01-04 23:20:00</td>\n",
       "      <td>376149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  candidate_id  liked\n",
       "8077960  2021-01-04 23:50:00       1890123      1\n",
       "9510021  2021-01-04 23:49:56       3204604      1\n",
       "9523742  2021-01-04 23:49:53       1643022      1\n",
       "5732380  2021-01-04 23:49:51       3825592      1\n",
       "9589743  2021-01-04 23:49:50        680198      1\n",
       "9821300  2021-01-04 23:49:47       1415704      1\n",
       "3512927  2021-01-04 23:49:43        107142      1\n",
       "8465051  2021-01-04 23:49:17       2793679      1\n",
       "8113628  2021-01-04 23:49:05        531340      1\n",
       "3758817  2021-01-04 23:42:18        981466      1\n",
       "5532510  2021-01-04 23:28:43        683003      1\n",
       "3626153  2021-01-04 23:28:36       1269010      1\n",
       "8512977  2021-01-04 23:28:34       1955273      1\n",
       "8076881  2021-01-04 23:28:25        247457      1\n",
       "3557910  2021-01-04 23:28:24       3190271      1\n",
       "8085602  2021-01-04 23:28:22        509739      1\n",
       "5640201  2021-01-04 23:28:20        123632      1\n",
       "9819908  2021-01-04 23:28:13       2285135      1\n",
       "3881326  2021-01-04 23:27:38       3268149      1\n",
       "3477194  2021-01-04 23:27:35       1480722      1\n",
       "7728033  2021-01-04 23:27:25        266061      1\n",
       "3779455  2021-01-04 23:27:24        687718      1\n",
       "9146270  2021-01-04 23:27:23        965911      1\n",
       "8124452  2021-01-04 23:27:18        172965      1\n",
       "8463678  2021-01-04 23:20:27       1920148      1\n",
       "8150459  2021-01-04 23:20:00        376149      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 268553 – Logged policy hit rate: 0.4230 (217/513 impressions)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'User 268553 – new recommendations (seen matches highlighted)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>score</th>\n",
       "      <th>seen_before</th>\n",
       "      <th>liked_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3866599</td>\n",
       "      <td>0.910172</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3869985</td>\n",
       "      <td>0.649383</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3853373</td>\n",
       "      <td>0.630649</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1890123</td>\n",
       "      <td>0.591339</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    candidate_id     score  seen_before  liked_before\n",
       "1        3866599  0.910172         True         False\n",
       "15       3869985  0.649383         True          True\n",
       "19       3853373  0.630649         True          True\n",
       "27       1890123  0.591339         True          True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'User 268553 – recent logged impressions (liked only)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8077960</th>\n",
       "      <td>2021-01-04 23:50:00</td>\n",
       "      <td>1890123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510021</th>\n",
       "      <td>2021-01-04 23:49:56</td>\n",
       "      <td>3204604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9523742</th>\n",
       "      <td>2021-01-04 23:49:53</td>\n",
       "      <td>1643022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732380</th>\n",
       "      <td>2021-01-04 23:49:51</td>\n",
       "      <td>3825592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9589743</th>\n",
       "      <td>2021-01-04 23:49:50</td>\n",
       "      <td>680198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9821300</th>\n",
       "      <td>2021-01-04 23:49:47</td>\n",
       "      <td>1415704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3512927</th>\n",
       "      <td>2021-01-04 23:49:43</td>\n",
       "      <td>107142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8465051</th>\n",
       "      <td>2021-01-04 23:49:17</td>\n",
       "      <td>2793679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113628</th>\n",
       "      <td>2021-01-04 23:49:05</td>\n",
       "      <td>531340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758817</th>\n",
       "      <td>2021-01-04 23:42:18</td>\n",
       "      <td>981466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532510</th>\n",
       "      <td>2021-01-04 23:28:43</td>\n",
       "      <td>683003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626153</th>\n",
       "      <td>2021-01-04 23:28:36</td>\n",
       "      <td>1269010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512977</th>\n",
       "      <td>2021-01-04 23:28:34</td>\n",
       "      <td>1955273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8076881</th>\n",
       "      <td>2021-01-04 23:28:25</td>\n",
       "      <td>247457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557910</th>\n",
       "      <td>2021-01-04 23:28:24</td>\n",
       "      <td>3190271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8085602</th>\n",
       "      <td>2021-01-04 23:28:22</td>\n",
       "      <td>509739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640201</th>\n",
       "      <td>2021-01-04 23:28:20</td>\n",
       "      <td>123632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819908</th>\n",
       "      <td>2021-01-04 23:28:13</td>\n",
       "      <td>2285135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881326</th>\n",
       "      <td>2021-01-04 23:27:38</td>\n",
       "      <td>3268149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477194</th>\n",
       "      <td>2021-01-04 23:27:35</td>\n",
       "      <td>1480722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728033</th>\n",
       "      <td>2021-01-04 23:27:25</td>\n",
       "      <td>266061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779455</th>\n",
       "      <td>2021-01-04 23:27:24</td>\n",
       "      <td>687718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9146270</th>\n",
       "      <td>2021-01-04 23:27:23</td>\n",
       "      <td>965911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8124452</th>\n",
       "      <td>2021-01-04 23:27:18</td>\n",
       "      <td>172965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8463678</th>\n",
       "      <td>2021-01-04 23:20:27</td>\n",
       "      <td>1920148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150459</th>\n",
       "      <td>2021-01-04 23:20:00</td>\n",
       "      <td>376149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  candidate_id  liked\n",
       "8077960  2021-01-04 23:50:00       1890123      1\n",
       "9510021  2021-01-04 23:49:56       3204604      1\n",
       "9523742  2021-01-04 23:49:53       1643022      1\n",
       "5732380  2021-01-04 23:49:51       3825592      1\n",
       "9589743  2021-01-04 23:49:50        680198      1\n",
       "9821300  2021-01-04 23:49:47       1415704      1\n",
       "3512927  2021-01-04 23:49:43        107142      1\n",
       "8465051  2021-01-04 23:49:17       2793679      1\n",
       "8113628  2021-01-04 23:49:05        531340      1\n",
       "3758817  2021-01-04 23:42:18        981466      1\n",
       "5532510  2021-01-04 23:28:43        683003      1\n",
       "3626153  2021-01-04 23:28:36       1269010      1\n",
       "8512977  2021-01-04 23:28:34       1955273      1\n",
       "8076881  2021-01-04 23:28:25        247457      1\n",
       "3557910  2021-01-04 23:28:24       3190271      1\n",
       "8085602  2021-01-04 23:28:22        509739      1\n",
       "5640201  2021-01-04 23:28:20        123632      1\n",
       "9819908  2021-01-04 23:28:13       2285135      1\n",
       "3881326  2021-01-04 23:27:38       3268149      1\n",
       "3477194  2021-01-04 23:27:35       1480722      1\n",
       "7728033  2021-01-04 23:27:25        266061      1\n",
       "3779455  2021-01-04 23:27:24        687718      1\n",
       "9146270  2021-01-04 23:27:23        965911      1\n",
       "8124452  2021-01-04 23:27:18        172965      1\n",
       "8463678  2021-01-04 23:20:27       1920148      1\n",
       "8150459  2021-01-04 23:20:00        376149      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 268553 – Logged policy hit rate: 0.4230 (217/513 impressions)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'User 268553 – new recommendations (seen matches highlighted)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_id</th>\n",
       "      <th>score</th>\n",
       "      <th>seen_before</th>\n",
       "      <th>liked_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3866599</td>\n",
       "      <td>0.910172</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3869985</td>\n",
       "      <td>0.649383</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3853373</td>\n",
       "      <td>0.630649</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1890123</td>\n",
       "      <td>0.591339</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    candidate_id     score  seen_before  liked_before\n",
       "1        3866599  0.910172         True         False\n",
       "15       3869985  0.649383         True          True\n",
       "19       3853373  0.630649         True          True\n",
       "27       1890123  0.591339         True          True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 268553 – Matched Hits@50: 0.7500 (3/4 seen recommendations)\n"
     ]
    }
   ],
   "source": [
    "k = 50\n",
    "example_users = [268553]\n",
    "comparison_results = {}\n",
    "for uid in example_users:\n",
    "    recent_logged, new_recs = compare_old_new_recommendations(uid, test_data, engine_test, k=k)\n",
    "    comparison_results[uid] = {'logged': recent_logged, 'new': new_recs}\n",
    "    display(f\"User {uid} – recent logged impressions (liked only)\")\n",
    "    display(recent_logged[recent_logged['liked'] == 1])\n",
    "    logged_hits_for_user(test_data, uid)\n",
    "    display(f\"User {uid} – new recommendations (seen matches highlighted)\")\n",
    "    if not new_recs.empty:\n",
    "        display(new_recs[new_recs['seen_before'] | new_recs['liked_before']])\n",
    "    print()\n",
    "    matched_hits_for_user(engine_test, uid, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a7bd2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "### OFF-POLICY NDCG@K (LOGGED IMPRESSIONS) ###\n",
      "======================================================================\n",
      "Users evaluated:                  30,327\n",
      "NDCG@100 (micro):                 0.8653\n",
      "Median per-user NDCG:            0.7328\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate the raw recommendation pairs\n",
    "pairs_df, overall_metrics = evaluate_classification_metrics(engine_test, test_data, sample_size=40000, k=100)\n",
    "\n",
    "print()\n",
    "\n",
    "# re-score using only impressions the user actually saw\n",
    "seen_pairs_df, seen_metrics = evaluate_classification_metrics_seen_only(pairs_df)\n",
    "\n",
    "print()\n",
    "\n",
    "# compute matched hits@K (off-policy precision style metric)\n",
    "matched_hits, topk_matched_pairs, per_user_matched = matched_hits_at_k(pairs_df, k=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matchmaker-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
