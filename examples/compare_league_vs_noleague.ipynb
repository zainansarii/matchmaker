{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9c41703",
   "metadata": {},
   "source": [
    "# League vs. No-League Recommender Comparison\n",
    "\n",
    "This notebook trains a fresh `MatchingEngine`, builds both the league-filtered and league-agnostic FAISS recommenders, and evaluates them on a held-out test split to compare mutual-match performance and coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04b76f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/matchmaker-dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from matchmaker import MatchingEngine\n",
    "from matchmaker.serving import LeagueFilteredRecommender, ALSFaissRecommender\n",
    "import cudf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90493800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading interaction data...\n",
      "Train rows: 7,862,310 | Test rows: 1,965,578\n"
     ]
    }
   ],
   "source": [
    "# Load data and create train/test split\n",
    "DATA_PATH = 'data/swipes_clean.csv'\n",
    "SPLIT_FRACTION = 0.8\n",
    "\n",
    "print('Loading interaction data...')\n",
    "raw_data = cudf.read_csv(DATA_PATH)\n",
    "raw_data = raw_data.sort_values('timestamp')\n",
    "split_idx = int(len(raw_data) * SPLIT_FRACTION)\n",
    "train_data = raw_data.iloc[:split_idx]\n",
    "test_data = raw_data.iloc[split_idx:]\n",
    "print(f'Train rows: {len(train_data):,} | Test rows: {len(test_data):,}')\n",
    "\n",
    "train_path = '/tmp/matchmaker_train_split.csv'\n",
    "test_path = '/tmp/matchmaker_test_split.csv'\n",
    "train_data.to_csv(train_path, index=False)\n",
    "test_data.to_csv(test_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c79e538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data... âœ…\n",
      "Fitting ALS... \n",
      "ðŸš€ Preparing data...\n",
      "ðŸŽ¯ Training maleâ†’female ALS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Training femaleâ†’male ALS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 334.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Converting factors to CuPy arrays...\n",
      "âœ… Trained M2F ALS with 31134 males Ã— 32994 females\n",
      "âœ… Trained F2M ALS with 9925 females Ã— 38446 males\n",
      "Complete! âœ…\n",
      "User DF updated âœ…\n",
      "User DF updated âœ…\n",
      "Building FAISS recommender... âœ…\n"
     ]
    }
   ],
   "source": [
    "# Train a new MatchingEngine on the training split\n",
    "engine = MatchingEngine()\n",
    "engine.load_interactions(\n",
    "    train_path,\n",
    "    decider_col='decidermemberid',\n",
    "    other_col='othermemberid',\n",
    "    like_col='like',\n",
    "    timestamp_col='timestamp',\n",
    "    gender_col='decidergender'\n",
    ")\n",
    "engine.run_engagement()\n",
    "engine.run_elo()\n",
    "engine.build_recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2464ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate both recommenders for comparison\n",
    "league_recommender = engine.recommender\n",
    "noleague_recommender = ALSFaissRecommender(als_model=engine.als_model, use_gpu=True)\n",
    "\n",
    "# Prepare shared user metadata dictionary\n",
    "if isinstance(engine.user_df, cudf.DataFrame):\n",
    "    user_df_pd = engine.user_df.to_pandas()\n",
    "else:\n",
    "    user_df_pd = engine.user_df.copy()\n",
    "\n",
    "user_metadata = {\n",
    "    row['user_id']: {\n",
    "        'gender': row['gender'],\n",
    "        'league': row.get('league'),\n",
    "    }\n",
    "    for _, row in user_df_pd.iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3676cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mutual_compatibility(recommender, test_data, gender='M', k=100, max_users=None):\n",
    "    \"\"\"Evaluate mutual compatibility for a given recommender on the held-out test set.\"\"\"\n",
    "    import cudf\n",
    "\n",
    "    rec_type = \"league-filtered\" if isinstance(recommender, LeagueFilteredRecommender) else \"no-league\"\n",
    "    print(f\"\\nEvaluating {rec_type} recommender for {gender} users...\")\n",
    "\n",
    "    # Step 1: collect positive interactions from the test split on GPU\n",
    "    test_likes = test_data[test_data['like'] == 1][['decidermemberid', 'othermemberid']]\n",
    "\n",
    "    # Step 2: pull gender information from engine.user_df (stay in cuDF)\n",
    "    if not isinstance(engine.user_df, cudf.DataFrame):\n",
    "        user_df_gpu = cudf.DataFrame.from_pandas(engine.user_df[['user_id', 'gender']])\n",
    "    else:\n",
    "        user_df_gpu = engine.user_df[['user_id', 'gender']]\n",
    "\n",
    "    gender_df = user_df_gpu.rename(columns={'user_id': 'decidermemberid'})\n",
    "    test_likes_with_gender = test_likes.merge(gender_df, on='decidermemberid', how='left')\n",
    "\n",
    "    # Step 3: build dictionaries of likes for deciders and receivers\n",
    "    if gender == 'M':\n",
    "        my_likes_series = (test_likes_with_gender[test_likes_with_gender['gender'] == 'M']\n",
    "                           .groupby('decidermemberid')['othermemberid']\n",
    "                           .agg(list))\n",
    "        their_likes_series = (test_likes_with_gender[test_likes_with_gender['gender'] == 'F']\n",
    "                              .groupby('decidermemberid')['othermemberid']\n",
    "                              .agg(list))\n",
    "        viewing_label = 'males viewing females'\n",
    "    else:\n",
    "        my_likes_series = (test_likes_with_gender[test_likes_with_gender['gender'] == 'F']\n",
    "                           .groupby('decidermemberid')['othermemberid']\n",
    "                           .agg(list))\n",
    "        their_likes_series = (test_likes_with_gender[test_likes_with_gender['gender'] == 'M']\n",
    "                              .groupby('decidermemberid')['othermemberid']\n",
    "                              .agg(list))\n",
    "        viewing_label = 'females viewing males'\n",
    "\n",
    "    # Convert grouped lists to compact Python structures (only once per user)\n",
    "    def _series_to_dict(list_series: cudf.Series) -> Dict[int, set]:\n",
    "        if list_series.empty:\n",
    "            return {}\n",
    "        keys = list_series.index.values_host.tolist()\n",
    "        values = list_series.to_arrow().to_pylist()\n",
    "        return {int(k): set(map(int, v)) for k, v in zip(keys, values)}\n",
    "\n",
    "    my_likes = _series_to_dict(my_likes_series)\n",
    "    their_likes = _series_to_dict(their_likes_series)\n",
    "\n",
    "    # Step 4: compute total mutual matches in the test set\n",
    "    total_mutual_matches = 0\n",
    "    for uid, liked_set in my_likes.items():\n",
    "        for other_id in liked_set:\n",
    "            if uid in their_likes.get(other_id, set()):\n",
    "                total_mutual_matches += 1\n",
    "\n",
    "    # Step 5: identify evaluation users using GPU set membership\n",
    "    eval_user_ids_gpu = cudf.Series(list(my_likes.keys()), dtype='int64')\n",
    "    valid_users_gpu = eval_user_ids_gpu[eval_user_ids_gpu.isin(user_df_gpu['user_id'])]\n",
    "    eval_user_ids = valid_users_gpu.values_host.tolist()\n",
    "\n",
    "    if max_users is not None:\n",
    "        eval_user_ids = eval_user_ids[:max_users]\n",
    "\n",
    "    if not eval_user_ids:\n",
    "        print('No eligible users found in test set.')\n",
    "        return None\n",
    "\n",
    "    # Step 6: gather metadata for these users (metadata dict may be on CPU already)\n",
    "    eval_metadata = {uid: user_metadata.get(uid, {}) for uid in eval_user_ids}\n",
    "\n",
    "    # Step 7: generate recommendations and measure runtime\n",
    "    start = time.perf_counter()\n",
    "    recs_batch = recommender.recommend_batch(eval_user_ids, eval_metadata, k=k)\n",
    "    runtime = time.perf_counter() - start\n",
    "\n",
    "    # Step 8: compute metrics on CPU-sized outputs\n",
    "    hits = 0\n",
    "    mutual_hits = 0\n",
    "    all_recs: List[int] = []\n",
    "    mutual_pairs: List[Tuple[int, int]] = []\n",
    "\n",
    "    for uid in tqdm(eval_user_ids, desc=f'Checking hits for {viewing_label}'):\n",
    "        recs = recs_batch.get(uid, [])\n",
    "        candidate_ids = [candidate for candidate, _ in recs]\n",
    "        all_recs.extend(candidate_ids)\n",
    "        actual_likes = my_likes.get(uid, set())\n",
    "        recommended_set = set(candidate_ids)\n",
    "        overlap = actual_likes & recommended_set\n",
    "        if overlap:\n",
    "            hits += 1\n",
    "            for other_id in overlap:\n",
    "                if uid in their_likes.get(other_id, set()):\n",
    "                    mutual_hits += 1\n",
    "                    mutual_pairs.append((uid, other_id))\n",
    "                    break\n",
    "\n",
    "    n_users = len(eval_user_ids)\n",
    "    hit_rate = hits / n_users\n",
    "    mutual_hit_rate = mutual_hits / n_users if n_users else 0\n",
    "    personalization = len(set(all_recs)) / len(all_recs) if all_recs else 0\n",
    "    recall_of_matches = mutual_hits / total_mutual_matches if total_mutual_matches else 0\n",
    "\n",
    "    return {\n",
    "        'gender': gender,\n",
    "        'k': k,\n",
    "        'users_evaluated': n_users,\n",
    "        'hit_rate': hit_rate,\n",
    "        'mutual_hit_rate': mutual_hit_rate,\n",
    "        'match_recall': recall_of_matches,\n",
    "        'personalization': personalization,\n",
    "        'unique_recs': len(set(all_recs)),\n",
    "        'total_recs': len(all_recs),\n",
    "        'runtime_seconds': runtime,\n",
    "        'mutual_pairs': mutual_pairs,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abfce38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating league-filtered recommender for M users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking hits for males viewing females: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19123/19123 [00:00<00:00, 132766.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating no-league recommender for M users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking hits for males viewing females: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19123/19123 [00:00<00:00, 143786.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating league-filtered recommender for F users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking hits for females viewing males: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4725/4725 [00:00<00:00, 140938.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating no-league recommender for F users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking hits for females viewing males: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4725/4725 [00:00<00:00, 126775.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run evaluations for both recommenders\n",
    "K = 100\n",
    "MAX_USERS = 20000  # cap evaluation users for practicality\n",
    "\n",
    "league_results_m = evaluate_mutual_compatibility(league_recommender, test_data, gender='M', k=K, max_users=MAX_USERS)\n",
    "noleague_results_m = evaluate_mutual_compatibility(noleague_recommender, test_data, gender='M', k=K, max_users=MAX_USERS)\n",
    "\n",
    "league_results_f = evaluate_mutual_compatibility(league_recommender, test_data, gender='F', k=K, max_users=MAX_USERS)\n",
    "noleague_results_f = evaluate_mutual_compatibility(noleague_recommender, test_data, gender='F', k=K, max_users=MAX_USERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58498522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>league_hit_rate</th>\n",
       "      <th>noleague_hit_rate</th>\n",
       "      <th>league_mutual_rate</th>\n",
       "      <th>noleague_mutual_rate</th>\n",
       "      <th>league_recall</th>\n",
       "      <th>noleague_recall</th>\n",
       "      <th>league_personalization</th>\n",
       "      <th>noleague_personalization</th>\n",
       "      <th>league_runtime_sec</th>\n",
       "      <th>noleague_runtime_sec</th>\n",
       "      <th>hit_rate_delta</th>\n",
       "      <th>mutual_rate_delta</th>\n",
       "      <th>recall_delta</th>\n",
       "      <th>personalization_delta</th>\n",
       "      <th>runtime_delta_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mâ†’F</td>\n",
       "      <td>0.4412</td>\n",
       "      <td>0.5195</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>4.2425</td>\n",
       "      <td>3.6530</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>-0.5895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fâ†’M</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>0.4721</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>-0.0234</td>\n",
       "      <td>-0.3713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  segment  league_hit_rate  noleague_hit_rate  league_mutual_rate  \\\n",
       "0     Mâ†’F           0.4412             0.5195              0.0093   \n",
       "1     Fâ†’M           0.0237             0.0322              0.0076   \n",
       "\n",
       "   noleague_mutual_rate  league_recall  noleague_recall  \\\n",
       "0                0.0132         0.0479           0.0679   \n",
       "1                0.0140         0.0097           0.0178   \n",
       "\n",
       "   league_personalization  noleague_personalization  league_runtime_sec  \\\n",
       "0                  0.0146                    0.0101              4.2425   \n",
       "1                  0.0321                    0.0086              0.8435   \n",
       "\n",
       "   noleague_runtime_sec  hit_rate_delta  mutual_rate_delta  recall_delta  \\\n",
       "0                3.6530          0.0783             0.0039        0.0199   \n",
       "1                0.4721          0.0085             0.0063        0.0081   \n",
       "\n",
       "   personalization_delta  runtime_delta_sec  \n",
       "0                -0.0046            -0.5895  \n",
       "1                -0.0234            -0.3713  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize results side-by-side\n",
    "def summarize_results(label, league_metrics, noleague_metrics):\n",
    "    return {\n",
    "        'segment': label,\n",
    "        'league_hit_rate': league_metrics['hit_rate'],\n",
    "        'noleague_hit_rate': noleague_metrics['hit_rate'],\n",
    "        'league_mutual_rate': league_metrics['mutual_hit_rate'],\n",
    "        'noleague_mutual_rate': noleague_metrics['mutual_hit_rate'],\n",
    "        'league_recall': league_metrics['match_recall'],\n",
    "        'noleague_recall': noleague_metrics['match_recall'],\n",
    "        'league_personalization': league_metrics['personalization'],\n",
    "        'noleague_personalization': noleague_metrics['personalization'],\n",
    "        'league_runtime_sec': league_metrics['runtime_seconds'],\n",
    "        'noleague_runtime_sec': noleague_metrics['runtime_seconds'],\n",
    "    }\n",
    "\n",
    "summary_df = pd.DataFrame([\n",
    "    summarize_results('Mâ†’F', league_results_m, noleague_results_m),\n",
    "    summarize_results('Fâ†’M', league_results_f, noleague_results_f),\n",
    "]).assign(\n",
    "    hit_rate_delta=lambda df: df['noleague_hit_rate'] - df['league_hit_rate'],\n",
    "    mutual_rate_delta=lambda df: df['noleague_mutual_rate'] - df['league_mutual_rate'],\n",
    "    recall_delta=lambda df: df['noleague_recall'] - df['league_recall'],\n",
    "    personalization_delta=lambda df: df['noleague_personalization'] - df['league_personalization'],\n",
    "    runtime_delta_sec=lambda df: df['noleague_runtime_sec'] - df['league_runtime_sec'],\n",
    ")\n",
    "\n",
    "summary_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matchmaker-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
